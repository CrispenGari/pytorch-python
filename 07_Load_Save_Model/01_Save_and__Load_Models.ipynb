{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Save_and _Load_Models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJjFgwJqyFAG"
      },
      "source": [
        "### Saving and Loading Models.\n",
        "When it comes to saving and loading models, there are three core functions to be familiar with:\n",
        "\n",
        "1. ``torch.save``: Saves a serialized object to disk.\n",
        "2. ``torch.load``: Uses pickle’s unpickling facilities to deserialize pickled object files to memory. \n",
        "3. ``torch.nn.Module.load_state_dict``: Loads a model’s parameter dictionary using a deserialized state_dict.\n",
        "\n",
        "What is `state_dict`?\n",
        "A ``state_dict`` is simply a Python dictionary object that maps each layer to its parameter tensor.\n",
        "\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFDs4ptWx-rQ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMeRzcc0z0H2"
      },
      "source": [
        "### Device Configuration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeueLtjXz8lq",
        "outputId": "6173434a-c975-4258-823d-ee926babf279"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cl55LHUx0KBG"
      },
      "source": [
        "### Loading the `cifar10` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78A1pgMm0R8e",
        "outputId": "f4874c9d-5a78-40fd-a5f2-1dea36c047f1"
      },
      "source": [
        "train = datasets.CIFAR10('content/drive/', train=True, transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))                                                    \n",
        "]), download=True)\n",
        "\n",
        "test = datasets.CIFAR10('content/drive/', train=False, transform=transforms.Compose([\n",
        "    transforms.ToTensor() ,\n",
        "       transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))                                                       \n",
        "]), download=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJypYbr42_Ja"
      },
      "source": [
        "### Class names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zxluKyy2-eQ",
        "outputId": "f48de375-502b-49d4-8fb0-d9cd6a2c21a9"
      },
      "source": [
        "class_names = train.classes\n",
        "class_names"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdkMzSsx0R4z"
      },
      "source": [
        "### ``Data Loader``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0ky4Qe10R2W"
      },
      "source": [
        "train_set = DataLoader(train, shuffle=True, batch_size=32)\n",
        "test_set = DataLoader(test, shuffle=False, batch_size=32)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJNvVjKm0R0L"
      },
      "source": [
        "for (x, y) in test_set:\n",
        "  pass"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "slZ9kuVL0RxH",
        "outputId": "3c4917cb-92a9-4b28-f571-840584a47755"
      },
      "source": [
        "plt.imshow(np.transpose(x[1].numpy(),(1, 2, 0)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f98e16e26d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5gBLc2P0RuL"
      },
      "source": [
        "n_channels = 3"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUIo9M-f0RrM"
      },
      "source": [
        "> Create a `CNN` for image classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_cj_2xm0Rll",
        "outputId": "e0e64b5f-b6cd-4ff4-90d8-2bb03efaccbb"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(n_channels, 64, (3, 3))\n",
        "    self.conv2 = nn.Conv2d(64, 128, (3, 3))\n",
        "    self.conv3 = nn.Conv2d(128, 64, (3, 3))\n",
        "\n",
        "    self._to_linear = None\n",
        "    self.x = torch.randn(3, 32, 32).view(-1, 3, 32, 32)\n",
        "    self.conv(self.x)\n",
        "\n",
        "    self.fc1 = nn.Linear(self._to_linear, 64)\n",
        "    self.fc2 = nn.Linear(64, 10)\n",
        "\n",
        "  def conv(self, x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "    x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
        "\n",
        "    if self._to_linear is None:\n",
        "      self._to_linear = x.shape[1] * x.shape[2] * x.shape[3]\n",
        "\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.conv(x)\n",
        "    x = x.view(-1, self._to_linear)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    return self.fc2(x)\n",
        "\n",
        "net = Net().to(device)\n",
        "net"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWS8jnlD0Rjq"
      },
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtQMYuM0Rgf"
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = list(y_true == y_pred).count(True)\n",
        "    total = len(y_true)\n",
        "  net.train()\n",
        "  return correct/total"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqiSzZ5S0Rdu",
        "outputId": "a9768b4d-43ca-4d88-fcfe-e871a9c40b2f"
      },
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  for idx, (X, y) in enumerate(train_set):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass\n",
        "    outputs = net(X)\n",
        "    # calc loss\n",
        "    loss = criterion(outputs, y)\n",
        "    # backward prop\n",
        "    loss.backward()\n",
        "    # update weights\n",
        "    optimizer.step()\n",
        "  acc = accuracy(torch.argmax(outputs, dim=1), y)\n",
        "  print(f\"Epochs: {epoch + 1}/{EPOCHS}, loss: {loss.item():.3f}, accurracy: {acc:.3f}\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 1/5, batch: 1563, loss: 0.858, accurracy: 0.688\n",
            "Epochs: 2/5, batch: 1563, loss: 1.494, accurracy: 0.500\n",
            "Epochs: 3/5, batch: 1563, loss: 1.021, accurracy: 0.500\n",
            "Epochs: 4/5, batch: 1563, loss: 0.911, accurracy: 0.688\n",
            "Epochs: 5/5, batch: 1563, loss: 0.337, accurracy: 0.875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GhYm4E20Ran",
        "outputId": "8347763c-4d7f-4bc4-9232-ceeea36c5aca"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in test_set:\n",
        "    X = data[0].to(device)\n",
        "    y = data[1].to(device)\n",
        "\n",
        "    predictions = net(X)\n",
        "    for i, j in enumerate(predictions):\n",
        "      predicted_class = torch.argmax(j)\n",
        "      real_class = y[i]\n",
        "      if real_class == predicted_class:\n",
        "        correct +=1\n",
        "      total +=1\n",
        "print(\"Accuracy: \", correct/total)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.7081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWKK0DoPD6eN"
      },
      "source": [
        "### Malking predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwNIsoHbD_1J"
      },
      "source": [
        "for X, y in test_set:\n",
        "  X = X.to(device)\n",
        "  y = y.to(device)\n",
        "  pass"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzxm5ey50RX5",
        "outputId": "81cff829-442a-4169-8523-f2d80f0cb47f"
      },
      "source": [
        "torch.argmax(net(X), dim=1), y"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([7, 3, 8, 0, 8, 4, 7, 0, 3, 5, 3, 3, 3, 5, 1, 7], device='cuda:0'),\n",
              " tensor([7, 5, 8, 0, 8, 2, 7, 0, 3, 5, 3, 8, 3, 5, 1, 7], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHUnP_xQ0RV5"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQncnrc_ErkW"
      },
      "source": [
        "### Saving the model and loading the Model.\n",
        "\n",
        "#### important methods\n",
        " 1. ``torch.save(arg, PATH)``\n",
        " 2. ``torch.load(PATH)``\n",
        " 3. ``torch.load_state_dict(arg)``\n",
        "\n",
        " ### Saving the model way number 1.\n",
        "\n",
        "1.0 Saving \n",
        "\n",
        " ```python\n",
        " model.save(model, path)\n",
        " ```\n",
        " 1.1 Loading\n",
        " ```python\n",
        " model.load(path)\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUJp4zig0RSb",
        "outputId": "94f74697-28d5-4e88-9201-300d4650b74d"
      },
      "source": [
        "path_1 = \"model_1.pth\"\n",
        "torch.save(net, path_1)\n",
        "print(\"Saved\")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q59rwmbB0RPj",
        "outputId": "4c01a6f2-d416-4a96-c79d-7075b996a7bc"
      },
      "source": [
        "model_1 = torch.load(path_1)\n",
        "model_1.eval() # or  model.train() very important"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mmPiqFL0RMr",
        "outputId": "ab78f60d-a719-4aee-89c1-f951a488bc0d"
      },
      "source": [
        "### Making predictions\n",
        "torch.argmax(model_1(X), dim=1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 3, 8, 0, 8, 4, 7, 0, 3, 5, 3, 3, 3, 5, 1, 7], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExhERmli0RKE"
      },
      "source": [
        "> Printing the model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADgK5cHm0RHK"
      },
      "source": [
        "for param in model_1.parameters():\n",
        "  print(param)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jSb08lGHCMb"
      },
      "source": [
        "### Saving the model way 2\n",
        "This is  the recommended way of saving pytorch models.\n",
        "\n",
        "1. Saving\n",
        "```python\n",
        "torch.save(model.state_dict(), PATH)\n",
        "```\n",
        "2. Loading\n",
        "When using this method, the model must be created again. We will show by example.\n",
        "\n",
        "```python\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval() # or  model.train() Very important step it tells pytorch that we want to evaluate our model.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nBvjANiIRx_"
      },
      "source": [
        "Saving."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "melVXMs90REd",
        "outputId": "f79b762b-68b8-4df2-bdc6-02fd055582bc"
      },
      "source": [
        "path_2 = \"model_2.pth\"\n",
        "torch.save(net.state_dict(), path_2)\n",
        "print(\"Saved\")"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ376WzoIVdo"
      },
      "source": [
        "print(net.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOYxRJ9wIVI2"
      },
      "source": [
        "net_1 = Net()\n",
        "net_1.load_state_dict(torch.load(path_2))\n",
        "net_1.eval()\n",
        "print(net_1.state_dict())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-CwM8W0RCB"
      },
      "source": [
        "### Creating  and Loading checkpoints\n",
        "\n",
        "01. Creating a checkpoint\n",
        "```python\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "checkpoint = {\n",
        "  \"epoch\": 13,\n",
        "  \"model_state\": model.state_dict(),\n",
        "  \"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "```\n",
        "\n",
        "02. Saving a checkpoint\n",
        "\n",
        "```python\n",
        "path = \"checkpoint_1.pth\"\n",
        "torch.save(checkpoint, path)\n",
        "```\n",
        "\n",
        "03. Loading a checkpoint\n",
        "\n",
        "```python\n",
        "model = Model()\n",
        "optimizer = optimizer = torch.optim.SGD(model.parameters(), lr=0)\n",
        "\n",
        "checkpoint = torch.load(FILE)\n",
        "model.load_state_dict(checkpoint['model_state'])\n",
        "optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "model.eval()\n",
        "```\n",
        "\n",
        "Example.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDdHDCDi0Q_c"
      },
      "source": [
        "optimizer = torch.optim.SGD(net.parameters(), lr=1e-3)\n",
        "checkpoint = {\n",
        "\"epoch\": 14,\n",
        "\"model_state\": net.state_dict(),\n",
        "\"optim_state\": optimizer.state_dict()\n",
        "}\n",
        "path = \"checkpoint_1.pth\""
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgDepWJk0Q9F",
        "outputId": "e2b688c5-455a-482a-f16a-7e4880f527a0"
      },
      "source": [
        "torch.save(checkpoint, path)\n",
        "print(\"Checkpoint saved.\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdXVuifN0Q6Z",
        "outputId": "16646060-ac5e-4127-c4c5-fa0042066ec8"
      },
      "source": [
        "net = Net()\n",
        "optimizer = optimizer = torch.optim.SGD(net.parameters(), lr=0)\n",
        " \n",
        "checkpoint = torch.load(path)\n",
        "net_state = net.load_state_dict(checkpoint['model_state'])\n",
        "optimizer_state = optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "epoch = checkpoint['epoch']\n",
        "\n",
        "net.eval() # or net.train()\n",
        "\n",
        "print(\"Net State: \", net_state)\n",
        "print(\"Epoch: \", epoch)\n",
        "print(\"Optimizer State: \", optimizer_state)\n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net State:  <All keys matched successfully>\n",
            "Epoch:  14\n",
            "Optimizer State:  None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLLElSlI0Q3x"
      },
      "source": [
        "#### Saving and Loading models on different devices.\n",
        "\n",
        "1. Save on GPU, Load on CPU\n",
        "````python\n",
        "device = torch.device(\"cuda\")\n",
        "net.to(device)\n",
        "torch.save(net.state_dict(), path)\n",
        "device = torch.device('cpu')\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(path, map_location=device))\n",
        "````\n",
        "\n",
        "2. Save on GPU, Load on GPU\n",
        "\n",
        "````python\n",
        "device = torch.device(\"cuda\")\n",
        "net.to(device)\n",
        "\n",
        "torch.save(net.state_dict(), path)\n",
        "\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(path))\n",
        "\n",
        "net.to(device)\n",
        "````\n",
        "\n",
        "3. Save on CPU, Load on GPU\n",
        "\n",
        "```python\n",
        "torch.save(net.state_dict(), path)\n",
        "device = torch.device(\"cuda\")\n",
        "\n",
        "net = Net()\n",
        "net.load_state_dict(torch.load(path, map_location=\"cuda:0\")) \n",
        "\n",
        "net.to(device)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wajX32wIN7xY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}