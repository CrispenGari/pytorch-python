{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "awful-semiconductor",
   "metadata": {},
   "source": [
    "## Neral Networks In Pytorch\n",
    "* We're just going to use data from Pytorch's \"torchvision.\" Pytorch has a relatively handy inclusion of a bunch of different datasets, including many for vision tasks, which is what torchvision is for.\n",
    "> Let's visualise the datatets that we can find in `torchvision`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-layer",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "opponent-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-advance",
   "metadata": {},
   "source": [
    "> The datasets `dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "engaged-hopkins",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIFAR10', 'CIFAR100', 'Caltech101', 'Caltech256', 'CelebA', 'Cityscapes', 'CocoCaptions', 'CocoDetection', 'DatasetFolder', 'EMNIST', 'FakeData', 'FashionMNIST', 'Flickr30k', 'Flickr8k', 'HMDB51', 'ImageFolder', 'ImageNet', 'KMNIST', 'Kinetics400', 'LSUN', 'LSUNClass', 'MNIST', 'Omniglot', 'PhotoTour', 'Places365', 'QMNIST', 'SBDataset', 'SBU', 'SEMEION', 'STL10', 'SVHN', 'UCF101', 'USPS', 'VOCDetection', 'VOCSegmentation', 'VisionDataset', 'WIDERFace', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'caltech', 'celeba', 'cifar', 'cityscapes', 'coco', 'fakedata', 'flickr', 'folder', 'hmdb51', 'imagenet', 'kinetics', 'lsun', 'mnist', 'omniglot', 'phototour', 'places365', 'sbd', 'sbu', 'semeion', 'stl10', 'svhn', 'ucf101', 'usps', 'utils', 'video_utils', 'vision', 'voc', 'widerface']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 75)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dir(datasets)), len(dir(datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-samoa",
   "metadata": {},
   "source": [
    "> We have `75` items that we can work with in the torchvision dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-maryland",
   "metadata": {},
   "source": [
    "### The MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-couple",
   "metadata": {},
   "source": [
    "The goal is to classify hand-written digits that comes from the `mnist` dataset as our `hello-world-neural-network`. This dataset contains images of handwritten digits from `0` to `9`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-emergency",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pointed-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                      transform = transforms.Compose({\n",
    "                          transforms.ToTensor()\n",
    "                      }))\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                      transform = transforms.Compose({\n",
    "                          transforms.ToTensor()\n",
    "                      }))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-accountability",
   "metadata": {},
   "source": [
    "> From the above cell we are just downloading the datasets and then transform or preprocess it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-ukraine",
   "metadata": {},
   "source": [
    "> Now, we need to handle for how we're going to iterate over that dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "atmospheric-latino",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-school",
   "metadata": {},
   "source": [
    "> **That was so brutal!! What is happening here?**\n",
    "\n",
    "**shuffle** - in ML normally we shuffle the data to mix it up so that the data will not have labels of the same type following each other.\n",
    "**batch_size** - this split our data in batches in our case a batch of `10` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "found-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]) tensor([7, 7])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for data in trainset:\n",
    "    print(data[0][:2], data[1][:2])\n",
    "    plt.imshow(data[0][0].view(28, 28), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-tactics",
   "metadata": {},
   "source": [
    "### Creating a NN\n",
    "* Now we have our trainset and testset let's start creating a Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "thorough-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-parks",
   "metadata": {},
   "source": [
    "> The `torch.nn` import gives us access to some helpful neural network things, such as various neural network layer types like:\n",
    " **regular fully-connected layers**, **convolutional layers** ..etc\n",
    " \n",
    "> The `torch.nn.functional` area specifically gives us access to some handy functions that we might not want to write ourselves. We will be using the **`relu`** or \"rectified linear unit\" activation function for our neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "polar-pension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net()\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enormous-guyana",
   "metadata": {},
   "source": [
    "> We have created a `Net` class which is inheriting from the `nn.Module` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cubic-contemporary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (FC1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (FC2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (FC3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (FC4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.FC1 = nn.Linear(28*28, 64)\n",
    "        self.FC2 = nn.Linear(64, 64 )\n",
    "        self.FC3 = nn.Linear(64, 64)\n",
    "        self.FC4 = nn.Linear(64, 10)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-tuesday",
   "metadata": {},
   "source": [
    "> Each of our `nn.Linear` layers expects the first parameter to be the input size, and the 2nd parameter is the output size. Note that the basic `Nural Network` expect a flattened array not a `28x28`. So at some point we must pass the flattened array.\n",
    "\n",
    "> The last layer **accepts 64 in_features and outputs 10** which is in our case the total number of unique labels.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-prescription",
   "metadata": {},
   "source": [
    "> Let's define a new method called `forward`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fifteen-emperor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (FC1): Linear(in_features=784, out_features=64, bias=True)\n",
       "  (FC2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (FC3): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (FC4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__();\n",
    "        self.FC1 = nn.Linear(28 * 28, 64)\n",
    "        self.FC2 = nn.Linear(64, 64)\n",
    "        self.FC3 = nn.Linear(64, 64)\n",
    "        self.FC4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.FC1(X)\n",
    "        X = self.FC2(X)\n",
    "        X = self.FC3(X)\n",
    "        X = self.FC4(X)\n",
    "        return X\n",
    "Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ready-sailing",
   "metadata": {},
   "source": [
    "> So `X` in this case is our input data, we will pass this to the first `FC1` and the output will be passed down to the `FC2` up to the `FC4` **And also remember that our `X` is a flattened array.**\n",
    "**Wait** Our layers are missing activation functions. In this case we are going to use `relu` as our activation function for  other layers and `log_softmax` for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "infrared-focus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.FC1 = nn.Linear(28 * 28, 64)\n",
    "        self.FC2 = nn.Linear(64, 64)\n",
    "        self.FC3 = nn.Linear(64, 64)\n",
    "        self.FC4 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.FC1(X))\n",
    "        X = F.relu(self.FC2(X))\n",
    "        X = F.relu(self.FC3(X))\n",
    "        X = F.log_softmax(self.FC4(X), dim=1)\n",
    "        return X\n",
    "    N\n",
    "\n",
    "X = torch.randn((28,28))\n",
    "\n",
    "X = X.view(-1, 28*28)\n",
    "net = Net()\n",
    "np.argmax(net(X).detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-holiday",
   "metadata": {},
   "source": [
    "### Training Our NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "convenient-nebraska",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x00000192D053A190>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "handled-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-honey",
   "metadata": {},
   "source": [
    "**loss** - this function calcualetes how far are our classifiaction from reality.\n",
    "**For one hot vectors** - `mean_square_error` is better to use.\n",
    "**For scalar classifictaion** - `cross_entropy` is better to use.\n",
    "\n",
    "> [Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "\n",
    "**optimizer** - this is what adjust the model's adjustable parameters like weights. The one that is popular is `Adam` (**Adaptive Momentum**) which takes a `lr` which has a default value of `0.001 or 1e-3`. The learning rate dictates the magnitude of changes that the optimizer can make at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-apache",
   "metadata": {},
   "source": [
    "> Now we can iterate over the data and see more about the **loss** we are going to define our `EPOCHS`\n",
    "too many epochs can result in the model `over-fitting` and too few epochs may result in the model `under-learning` the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "governmental-germany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS 1/3\n",
      "tensor(0.0112, grad_fn=<NllLossBackward>)\n",
      "EPOCHS 2/3\n",
      "tensor(0.2175, grad_fn=<NllLossBackward>)\n",
      "EPOCHS 3/3\n",
      "tensor(0.2117, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"EPOCHS {epoch+1}/{EPOCHS }\")\n",
    "    for data in trainset:\n",
    "        X, y = data # a batch of 10 features and 10 labels\n",
    "        net.zero_grad() # sets gradients to 0 before loss calulated\n",
    "        output = net(X.view(-1,784)) ## pass the flattened image\n",
    "        \n",
    "        ## calculate the loss value\n",
    "        loss = F.nll_loss(output, y)\n",
    "        # apply this loss backwards thru the network's parameters\n",
    "        loss.backward() \n",
    "        # attempt to optimize weights to account for loss/gradients\n",
    "        optimizer.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-blond",
   "metadata": {},
   "source": [
    "The `net.zero_grad()` is a very important step, otherwise these gradients will add up for every pass, and then we'll be re-optimizing for previous gradients that we already optimized for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reverse-webster",
   "metadata": {},
   "source": [
    "### Calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "associate-partition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.971\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        \n",
    "        for i, j in enumerate(output):\n",
    "            if torch.argmax(j) == y[i]:\n",
    "                correct +=1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-sample",
   "metadata": {},
   "source": [
    "> Our model is `97%` accurate on the `testset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ongoing-treasurer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9787666666666667\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        \n",
    "        for i, j in enumerate(output):\n",
    "            if torch.argmax(j) == y[i]:\n",
    "                correct +=1\n",
    "            total += 1\n",
    "print(\"Accuracy: \", correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-heritage",
   "metadata": {},
   "source": [
    "> Our model is `98%` accurate on the trainset. Which is closer to `97%` which means we are not overfitting or underfitting the model. Our model is learning fine with `3` epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-stable",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "automated-walnut",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X in trainset:\n",
    "    X, y = X\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "silver-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x192d04a7eb0>, tensor(3))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].view(28,28), cmap=\"gray\"), y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "intense-marine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3, dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions  = net(X[0].view(-1, 28*28))\n",
    "torch.argmax(predictions).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-gather",
   "metadata": {},
   "source": [
    "> The model is cool in predicting the digit `3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-giving",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
