{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12_French_To_English_Short_Phrases.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiB2HyprlmBf"
      },
      "source": [
        "### Frencsh t english short phrases\n",
        "\n",
        "In this notebook we are going to create a simple model that translate senetence from french to english. We are going to leran how we can load the dataset from our local file and prepare it for training. We are in google colab, as usual we are going to use google drive as our local storage. I've a text file that contains the following data in it:\n",
        "\n",
        "```\n",
        "Go.\tVa !\n",
        "Hi.\tSalut !\n",
        "Run!\tCours !\n",
        "Run!\tCourez !\n",
        "Wow!\tÇa alors !\n",
        "...\n",
        "```\n",
        "\n",
        "In this toy dataset we are not going to have a test dataset since the dataset is very small.\n",
        "\n",
        "We are going to create two files:\n",
        "\n",
        "```\n",
        "fr.txt -> contains all french phrases that matches the eng phrases\n",
        "en.txt -> contains all english phrases that matches the french phrases\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz8CdMAVkV12"
      },
      "source": [
        "import os \n",
        "import time\n",
        "import io"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hOuhNOrm3WS"
      },
      "source": [
        "### Mounting the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5c_asQ-m2XR"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC5efqSXnlkL"
      },
      "source": [
        "\n",
        "base_path = '/content/drive/MyDrive/NLP Data/seq2seq/fr-en-short-phrases'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QvFp4Qfn3Yi"
      },
      "source": [
        "Creating two text files one for french and the otherone for english."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NDyvk1jn2vL",
        "outputId": "f9647da1-8b35-4b33-ef71-f51ac06022c6"
      },
      "source": [
        "fr_path = \"fr.txt\"\n",
        "en_path = \"en.txt\"\n",
        "\n",
        "rows = open(os.path.join(base_path, 'fra.txt'), encoding='utf8').read().split('\\n')\n",
        "\n",
        "eng = []\n",
        "fra = []\n",
        "for row in rows:\n",
        "  try:\n",
        "    en, fr = row.split('\\t')\n",
        "    eng.append(en)\n",
        "    fra.append(fr)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "with open(os.path.join(base_path, 'fr.txt'), 'w') as f:\n",
        "  for line in fra:\n",
        "    f.write(line+'\\n')\n",
        "with open(os.path.join(base_path, 'en.txt'), 'w') as f:\n",
        "  for line in eng:\n",
        "    f.write(line+'\\n')\n",
        "print(\"done\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFqlsRtbrOjQ"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIIcKftdqoyo"
      },
      "source": [
        "import torch\n",
        "import time, os, math, random\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchtext.legacy.vocab import Vocab\n",
        "import numpy as np\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "from collections import Counter"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMimLqamrQSI"
      },
      "source": [
        "### SEEDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8IkhRbirTpI"
      },
      "source": [
        "SEED = 42\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNcFcSNAqkir"
      },
      "source": [
        "### Next we will create `tokenizers`\n",
        "\n",
        "We are going to use two tokenizers, one for `english` and the other one for `french`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "un9q4CTrol9Z"
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFnD9zrHraKx"
      },
      "source": [
        "fr_tokenizer = get_tokenizer('spacy', language=\"fr\")\n",
        "en_tokenizer = get_tokenizer('spacy', language=\"en\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RUju29mrwvS"
      },
      "source": [
        "### Building the vocabulary\n",
        "WE are goig to create a function called `build_vocab()` that will read data from our local files and build the vocabulary for us. We are going to set the `min_freq=1` so that the token that appears less than 1 times will be automatically converted to unknown."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW_1gtTzrrx-"
      },
      "source": [
        "def build_vocab(filepath, tokenizer):\n",
        "  counter = Counter()\n",
        "\n",
        "  with open(os.path.join(base_path, filepath), 'r', encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "      counter.update(tokenizer(line.lower()))\n",
        "  return Vocab(counter=counter, min_freq=2, specials=('<unk>', '<pad>', '<sos>', '<eos>'), specials_first=True)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQqqwV06tNN4"
      },
      "source": [
        "fr_vocab = build_vocab(fr_path, fr_tokenizer)\n",
        "en_vocab = build_vocab(en_path, en_tokenizer)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsT5gn7NuExh"
      },
      "source": [
        "### Data processing.\n",
        "\n",
        "We are going to create a function that is called `data_process` that will tokenize each sentence and returns vectors representation of each word in a senetence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq8GliFltgnU"
      },
      "source": [
        "def data_process(fr_path:str, en_path: str):\n",
        "  raw_fr_iter = iter(io.open(os.path.join(base_path, fr_path), encoding=\"utf8\"))\n",
        "  raw_en_iter = iter(io.open(os.path.join(base_path, en_path), encoding=\"utf8\"))\n",
        "  data = []\n",
        "  for raw_fr, raw_en in zip(raw_fr_iter, raw_en_iter):\n",
        "    fr_tensor = torch.tensor([fr_vocab[token] for token in fr_tokenizer(raw_fr)])\n",
        "    en_tensor = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)])\n",
        "    data.append([fr_tensor, en_tensor])\n",
        "  return data"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J41XmucpvjkP"
      },
      "source": [
        "data = data_process(fr_path, en_path)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o9Nq5hhv4c9",
        "outputId": "d89b3974-489e-47db-89c0-c3c84f6f8f63"
      },
      "source": [
        "data[:2]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[tensor([ 0, 42,  4]), tensor([0, 5, 4])],\n",
              " [tensor([ 0, 42,  4]), tensor([0, 5, 4])]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHb-34bvv-cl"
      },
      "source": [
        "### Splitting the train and validation data.\n",
        "\n",
        "In this case we are going to use `sklearn` to split the data into train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRispxljwOFY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Gq0XAyHwTan"
      },
      "source": [
        "train_data, val_data = train_test_split(data, test_size=.2, random_state=SEED)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QuzJvKhwpXb"
      },
      "source": [
        "### Checking how many examples Do we have for each set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fskhFd-qwTXl",
        "outputId": "33b169e5-f442-45ee-9029-79809ad255d5"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate(column_names, data):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= \"VISUALIZING SETS EXAMPLES\"\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'r'\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "column_names = [\"SUBSET\", \"EXAMPLE(s)\"]\n",
        "row_data = [\n",
        "        [\"training\", len(train_data)],\n",
        "        ['validation', len(val_data)],\n",
        "]\n",
        "tabulate(column_names, row_data)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------------------------+\n",
            "|  VISUALIZING SETS EXAMPLES  |\n",
            "+--------------+--------------+\n",
            "| SUBSET       |   EXAMPLE(s) |\n",
            "+--------------+--------------+\n",
            "| training     |       128697 |\n",
            "| validation   |        32175 |\n",
            "+--------------+--------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycSIITrVxGKO"
      },
      "source": [
        "### Helper functions.\n",
        "\n",
        "Let's create a function that converts sequences to string representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QanHkPafwTUB"
      },
      "source": [
        "def seq_to_text(seq):\n",
        "  reversed_vocab_eng = dict((v, k) for (k, v) in en_vocab.stoi.items())\n",
        "  reversed_vocab_fra = dict((v, k) for (k, v) in fr_vocab.stoi.items())\n",
        "  en = \" \".join(reversed_vocab_eng[i.item()] for i in seq[1])\n",
        "  fr = \" \".join(reversed_vocab_fra[i.item()] for i in seq[0])\n",
        "  return en, fr\n",
        "\n",
        "for i in range(10, 20):\n",
        "  print(seq_to_text(train_data[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5l7YQiuz2RW"
      },
      "source": [
        "### DataLoader\n",
        "\n",
        "Now it's time to create our dataset from tensors using dataloader. But first let's create a device variable.\n",
        "\n",
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOyJFi3u0E4J",
        "outputId": "0852a460-5fed-4df7-84f5-666b6c64e928"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv9E2_550UtE"
      },
      "source": [
        "### Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hai4lGdD0N1Q",
        "outputId": "86258b31-373f-4f93-c955-3dd061eac315"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "PAD_IDX = fr_vocab['<pad>']\n",
        "SOS_IDX = fr_vocab['<sos>']\n",
        "EOS_IDX = fr_vocab['<eos>']\n",
        "PAD_IDX, SOS_IDX, EOS_IDX"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg_EX-Bd0jEe"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzvhN7pG0092"
      },
      "source": [
        "### Generating bactches\n",
        "\n",
        "We are going to create a `generate_batch` function that will generate the batch for us.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1jYiQd20_q8"
      },
      "source": [
        "def generate_batch(data_batch):\n",
        "  fr_batch = []\n",
        "  en_batch = []\n",
        "  for fr_item, en_item in data_batch:\n",
        "    fr_batch.append(\n",
        "        torch.cat([\n",
        "            torch.tensor([SOS_IDX]),\n",
        "            fr_item,\n",
        "            torch.tensor([EOS_IDX])\n",
        "        ], dim=0)\n",
        "    )\n",
        "    en_batch.append(\n",
        "        torch.cat([\n",
        "            torch.tensor([SOS_IDX]),\n",
        "            en_item,\n",
        "            torch.tensor([EOS_IDX])\n",
        "        ], dim=0)\n",
        "    )\n",
        "\n",
        "  fr_batch = pad_sequence(fr_batch, padding_value=PAD_IDX)\n",
        "  en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "  return fr_batch, en_batch\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKBn-Ooh2Mv0"
      },
      "source": [
        "### Creating iterators.\n",
        "\n",
        "Now we will then create an iterators, we only have two iterators which are the `train_iterator` and the `test_iterator`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmbc585W0fdA"
      },
      "source": [
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyBBokcs2npn"
      },
      "source": [
        "### Finally we create the model.\n",
        "\n",
        "We are going to create an `Seq2Seq` model based on [this](https://github.com/CrispenGari/pytorch-python/blob/main/09_TorchText/03_Sequence_To_Sequence/11_Language_Translation_With_Torchtext_Custom_datasetworked.ipynb) notebook.\n",
        "\n",
        "\n",
        "### Encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-omUyVSS2c2n"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, \n",
        "               input_dim,\n",
        "               emb_dim,\n",
        "               enc_hid_dim,\n",
        "               dec_hid_dim,\n",
        "               dropout\n",
        "               ):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.emb_dim = emb_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.dropout = dropout\n",
        "\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "    self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "    self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, src):\n",
        "    embedded = self.dropout(self.embedding(src))\n",
        "    outputs, hidden = self.rnn(embedded)\n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "    return outputs, hidden"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtMwdv9j3MgT"
      },
      "source": [
        "### Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1vmpvjr3TeM"
      },
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self,\n",
        "              enc_hid_dim,\n",
        "              dec_hid_dim,\n",
        "              attn_dim\n",
        "               ):\n",
        "    super(Attention, self).__init__()\n",
        "\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "    self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "  def forward(self,\n",
        "              decoder_hidden,\n",
        "              encoder_outputs\n",
        "              ):\n",
        "    src_len = encoder_outputs.shape[0]\n",
        "    repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "    energy = torch.tanh(self.attn(torch.cat((\n",
        "        repeated_decoder_hidden,\n",
        "        encoder_outputs),\n",
        "        dim = 2)))\n",
        "    attention = torch.sum(energy, dim=2)\n",
        "    return F.softmax(attention, dim=1)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xiAZucl3KYD"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8PLoMS03GPL"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self,\n",
        "               output_dim,\n",
        "               emb_dim,\n",
        "               enc_hid_dim,\n",
        "               dec_hid_dim,\n",
        "               dropout,\n",
        "               attention\n",
        "               ):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.emb_dim = emb_dim\n",
        "    self.enc_hid_dim = enc_hid_dim\n",
        "    self.dec_hid_dim = dec_hid_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.dropout = dropout\n",
        "    self.attention = attention\n",
        "\n",
        "    self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "    self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "    self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def _weighted_encoder_rep(self,\n",
        "                            decoder_hidden,\n",
        "                            encoder_outputs\n",
        "                            ):\n",
        "    a = self.attention(decoder_hidden, encoder_outputs)\n",
        "    a = a.unsqueeze(1)\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "    weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "    weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "    return weighted_encoder_rep\n",
        "\n",
        "  def forward(self,\n",
        "              input,\n",
        "              decoder_hidden,\n",
        "              encoder_outputs,\n",
        "             ):\n",
        "    input = input.unsqueeze(0)\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                      encoder_outputs)\n",
        "    rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "    output, decoder_hidden = self.rnn(rnn_input, \n",
        "                                      decoder_hidden.unsqueeze(0)\n",
        "                                      )\n",
        "    embedded = embedded.squeeze(0)\n",
        "    output = output.squeeze(0)\n",
        "    weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "    output = self.out(torch.cat((output,\n",
        "                                  weighted_encoder_rep,\n",
        "                                  embedded), dim = 1))\n",
        "\n",
        "    return output, decoder_hidden.squeeze(0)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpa2Da473Ncd"
      },
      "source": [
        "### Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G39HtSXz3GNK"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,\n",
        "                 encoder,\n",
        "                 decoder,\n",
        "                 device):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "    \n",
        "  def forward(self, src, trg, teacher_forcing_ratio=.5):\n",
        "    batch_size = src.shape[1]\n",
        "    max_len = trg.shape[0]\n",
        "    trg_vocab_size = self.decoder.output_dim\n",
        "    outputs = torch.zeros(max_len, batch_size,\n",
        "                          trg_vocab_size).to(self.device)\n",
        "    encoder_outputs, hidden = self.encoder(src)\n",
        "    # first input to the decoder is the <sos> token\n",
        "    output = trg[0,:]\n",
        "    for t in range(1, max_len):\n",
        "      output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "      outputs[t] = output\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\n",
        "      top1 = output.max(1)[1]\n",
        "      output = (trg[t] if teacher_force else top1)\n",
        "      \n",
        "    return outputs"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii-dvmPc4iOi"
      },
      "source": [
        "### Model Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0bo7GyK3GEx"
      },
      "source": [
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ATTN_DIM = 64\n",
        "# ENC_DROPOUT = 0.5\n",
        "# DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "INPUT_DIM = len(fr_vocab)\n",
        "OUTPUT_DIM = len(en_vocab)"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfpcsEAX4uz2"
      },
      "source": [
        "### Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhUA9H853GAH",
        "outputId": "be76b9f2-7e8f-4705-edf1-a261a5343f4e"
      },
      "source": [
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "model"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(15265, 32)\n",
              "    (rnn): GRU(32, 64, bidirectional=True)\n",
              "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=192, out_features=8, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(9540, 32)\n",
              "    (rnn): GRU(160, 64)\n",
              "    (out): Linear(in_features=224, out_features=9540, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EbsYYMD5Csj"
      },
      "source": [
        "### Initializing the weights for the `model`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vENGdxE_3F8-"
      },
      "source": [
        "def init_weights(m: nn.Module):\n",
        "  for name, param in m.named_parameters():\n",
        "    if 'weight' in name:\n",
        "      nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "    else:\n",
        "      nn.init.constant_(param.data, 0)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpJxDuqQ3FwE"
      },
      "source": [
        "### Applying the weights to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh8Mzk3r5QBm",
        "outputId": "f2bfed58-ede5-4f33-945c-70fd56be3140"
      },
      "source": [
        "model.apply(init_weights)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(15265, 32)\n",
              "    (rnn): GRU(32, 64, bidirectional=True)\n",
              "    (fc): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (attention): Attention(\n",
              "      (attn): Linear(in_features=192, out_features=8, bias=True)\n",
              "    )\n",
              "    (embedding): Embedding(9540, 32)\n",
              "    (rnn): GRU(160, 64)\n",
              "    (out): Linear(in_features=224, out_features=9540, bias=True)\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltncIkrN5Vg7"
      },
      "source": [
        "### Model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpqwY_Ws5TFS",
        "outputId": "aa1c5116-ebe6-494a-ac79-719473900a2d"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of paramaters: 3,031,084\n",
            "Total tainable parameters: 3,031,084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g67i_oxF5a-5"
      },
      "source": [
        "The model have `~30M` trainable parameters.\n",
        "\n",
        "\n",
        "### Next.\n",
        "\n",
        "We are going to create the `optimizer` and `criterion`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQ_XWkdp5ZuZ"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "PAD_IDX = en_vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(device)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJ9Pcu-z51MK"
      },
      "source": [
        "### Training and Evaluation loops."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z6GYsRG5t07"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  for _, (src, trg) in enumerate(iterator):\n",
        "      src, trg = src.to(device), trg.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(src, trg)\n",
        "      output = output[1:].view(-1, output.shape[-1])\n",
        "      trg = trg[1:].view(-1)\n",
        "\n",
        "      loss = criterion(output, trg)\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for _, (src, trg) in enumerate(iterator):\n",
        "      src, trg = src.to(device), trg.to(device)\n",
        "      output = model(src, trg, 0) #turn off teacher forcing\n",
        "      output = output[1:].view(-1, output.shape[-1])\n",
        "      trg = trg[1:].view(-1)\n",
        "      loss = criterion(output, trg)\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "  return epoch_loss / len(iterator)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXCcAkag58I9"
      },
      "source": [
        "### Helper functions.\n",
        "\n",
        "1. time to string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01D651Zs57kF"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBj22V_s6ZdW"
      },
      "source": [
        "2. Tabulate training epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBFuzrih6Y8z"
      },
      "source": [
        "def tabulate_training(column_names, data, title):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'r'\n",
        "  table.align[column_names[2]] = 'r'\n",
        "  table.align[column_names[3]] = 'r'\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntoblb-R6YE0",
        "outputId": "33a1211d-286c-4538-c9cd-5df495980941"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "column_names = [\"SET\", \"LOSS\", \"PPL\", \"ETA\"]\n",
        "print(\"TRAINING STARTS....\")\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "  valid_loss = evaluate(model, valid_iter, criterion)\n",
        "  end = time.time()\n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} | {'saving model...' if valid_loss < best_valid_loss else 'not saving...'}\" \n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), 'best-model.pt')\n",
        "  rows_data =[\n",
        "        [\"train\", f\"{train_loss:.3f}\", f\"{math.exp(train_loss):7.3f}\", hms_string(end - start) ],\n",
        "        [\"val\", f\"{valid_loss:.3f}\", f\"{math.exp(train_loss):7.3f}\", '' ]\n",
        "  ]\n",
        "  tabulate_training(column_names, rows_data, title)\n",
        "\n",
        "print(\"TRAINING ENDS....\")\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING STARTS....\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 01/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 4.222 |  68.154 | 0:03:17.99 |\n",
            "| val   | 4.154 |  68.154 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 02/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 3.601 |  36.643 | 0:03:18.18 |\n",
            "| val   | 3.974 |  36.643 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 03/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 3.426 |  30.750 | 0:03:18.33 |\n",
            "| val   | 3.764 |  30.750 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 04/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 3.226 |  25.173 | 0:03:17.20 |\n",
            "| val   | 3.518 |  25.173 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 05/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.963 |  19.355 | 0:03:16.31 |\n",
            "| val   | 3.218 |  19.355 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 06/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.730 |  15.326 | 0:03:17.73 |\n",
            "| val   | 2.988 |  15.326 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 07/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.529 |  12.535 | 0:03:18.84 |\n",
            "| val   | 2.815 |  12.535 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 08/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.373 |  10.731 | 0:03:19.38 |\n",
            "| val   | 2.703 |  10.731 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 09/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.246 |   9.448 | 0:03:19.58 |\n",
            "| val   | 2.602 |   9.448 |            |\n",
            "+-------+-------+---------+------------+\n",
            "+--------------------------------------+\n",
            "|    EPOCH: 10/10 | saving model...    |\n",
            "+-------+-------+---------+------------+\n",
            "| SET   |  LOSS |     PPL |        ETA |\n",
            "+-------+-------+---------+------------+\n",
            "| train | 2.145 |   8.541 | 0:03:18.73 |\n",
            "| val   | 2.522 |   8.541 |            |\n",
            "+-------+-------+---------+------------+\n",
            "TRAINING ENDS....\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrhK5rSU7KVT"
      },
      "source": [
        "### Evaluating the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzsbg2tC7J_i",
        "outputId": "9d4310a5-11c5-4953-cf43-71009e25f312"
      },
      "source": [
        "model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "test_loss = evaluate(model, valid_iter, criterion)\n",
        "title = \"Model Evaluation Summary\"\n",
        "data_rows = [[\"Test\", f'{test_loss:.3f}', f'{math.exp(test_loss):7.3f}', \"\"]]\n",
        "\n",
        "tabulate_training([\"SET\", \"LOSS\", \"PPL\", \"ETA\"], data_rows, title)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------------------+\n",
            "|   Model Evaluation Summary   |\n",
            "+------+-------+---------+-----+\n",
            "| SET  |  LOSS |     PPL | ETA |\n",
            "+------+-------+---------+-----+\n",
            "| Test | 2.523 |  12.467 |     |\n",
            "+------+-------+---------+-----+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NkMB-Jo7FHy"
      },
      "source": [
        "### Model Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdnMwRunFxpv",
        "outputId": "393ae3f8-3a82-4648-a0b0-7e0b9300a086"
      },
      "source": [
        "en_vocab.stoi[\"<sos>\"]\n",
        "\n",
        "en_tokenizer(\"this is the boy\")"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'the', 'boy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-37tdIxa6-bt",
        "outputId": "5c5aae48-ccc4-4e50-9afa-87fa769bc0c0"
      },
      "source": [
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
        "    model.eval()\n",
        "    if isinstance(sentence, str):\n",
        "        tokens = [token.lower() for token in fr_tokenizer(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [\"<sos>\"] + tokens + [\"<eos>\"]\n",
        "    src_indexes = [src_field.stoi[token] for token in tokens]\n",
        "\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "      encoder_outputs, hidden = model.encoder(src_tensor)\n",
        "    trg_indexes = [trg_field.stoi[\"<sos>\"]]\n",
        "    for i in range(max_len):\n",
        "      trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
        "      with torch.no_grad():\n",
        "        output, hidden = model.decoder(trg_tensor, hidden, encoder_outputs)\n",
        "      pred_token = output.argmax(1).item()\n",
        "      trg_indexes.append(pred_token)\n",
        "      if pred_token == trg_field.stoi['<eos>']:\n",
        "        break\n",
        "\n",
        "    trg_tokens = [trg_field.itos[i] for i in trg_indexes]\n",
        "    return trg_tokens\n",
        "translate_sentence(\"va\", fr_vocab, en_vocab, model, device, max_len = 50)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>', '<unk>', 'has', 'a', 'talented', '.', '\\n', '<eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdxnDr56SZKK"
      },
      "source": [
        "### Let's make some predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcBaJucHTNsp"
      },
      "source": [
        "def tabulate_translations(column_names, data, title, max_characters=25):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title= title\n",
        "  table.align[column_names[0]] = 'l'\n",
        "  table.align[column_names[1]] = 'l'\n",
        "\n",
        "  table._max_width = {column_names[0] :max_characters, column_names[1] :max_characters}\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "columns_names = [\n",
        "    \"FR (real src sentence)\", \"EN (translated version)\"\n",
        "]\n",
        "title = \"FRENCH to ENGLISH TRANSLATOR\""
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF0aA-fzSY74",
        "outputId": "ea7cf5a9-c9c3-43fb-d321-50ff046bb2db"
      },
      "source": [
        "i = 0\n",
        "with open(os.path.join(base_path, fr_path), encoding=\"utf8\") as f:\n",
        "  for index, line in enumerate(f):\n",
        "    if index % 12 == 0:\n",
        "      i += 1\n",
        "      translation = translate_sentence(line, fr_vocab, en_vocab, model, device, max_len = 50)\n",
        "      tabulate_translations(columns_names, [[line, \" \".join(translation)]], title=title)\n",
        "    if i == 10:\n",
        "      break\n"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| Va !                   | <sos> <unk> 's !        |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n",
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| Attendez !             | <sos> <unk> 's !        |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n",
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| Attaquez !             | <sos> <unk> 's !        |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n",
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| Compris ?              | <sos> <unk> you you ?   |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n",
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| J'ai 19 ans.           | <sos> <unk> have a .    |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n",
            "+----------------------------------------------------+\n",
            "|            FRENCH to ENGLISH TRANSLATOR            |\n",
            "+------------------------+---------------------------+\n",
            "| FR (real src sentence) | EN (translated version)   |\n",
            "+------------------------+---------------------------+\n",
            "| Hors de question !     | <sos> <unk> 're going to  |\n",
            "|                        | question .                |\n",
            "|                        |  <eos>                    |\n",
            "+------------------------+---------------------------+\n",
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| Sois calme !           | <sos> <unk> 's !        |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n",
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| Sois gentille !        | <sos> <unk> kind of !   |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n",
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| Entre !                | <sos> <unk> 's !        |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n",
            "+--------------------------------------------------+\n",
            "|           FRENCH to ENGLISH TRANSLATOR           |\n",
            "+------------------------+-------------------------+\n",
            "| FR (real src sentence) | EN (translated version) |\n",
            "+------------------------+-------------------------+\n",
            "| Sortez !               | <sos> <unk> 's !        |\n",
            "|                        |  <eos>                  |\n",
            "+------------------------+-------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y9KiQ-YUmaX"
      },
      "source": [
        "### Conclusion.\n",
        "\n",
        "There's still a lot of things to cover. Next we will try to make accurate translation as you can see that this model did not perform well during inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiHGFIrrT6Z3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}