{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "portable-storage",
   "metadata": {},
   "source": [
    "## Creating a Convolutional Neural Network-Dogs-v-Cats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-spectrum",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informal-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-customer",
   "metadata": {},
   "source": [
    "### Creating a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "significant-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (3,3))\n",
    "        self.conv2 = nn.Conv2d(32, 64, (3,3))\n",
    "        self.conv3 = nn.Conv2d(64, 64, (3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-example",
   "metadata": {},
   "source": [
    "> The layers input and output size, and a kernel size of `3x3` which is also known as the kennel window. The first `conv1` will output `32` which will be the input of `conv2` which has a kernel size of `3x3` and outputing `64`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-tokyo",
   "metadata": {},
   "source": [
    "> Now we need to flatten the output at some point to a `dense` layer with an activation function, because now if we look at the last layer it is not flat. So we need to flatten the output of the last layer before passing it to the dense layer. **How do we do that?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-coffee",
   "metadata": {},
   "source": [
    "> We are ging to solve this by creating a fake, torch tesor and get the shape of the last `conv` by applying some max_pooling in the `conv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "billion-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, (3,3))\n",
    "        self.conv2 = nn.Conv2d(32, 64, (3,3))\n",
    "        self.conv3 = nn.Conv2d(64, 128, (3,3))\n",
    "        self.x = torch.randn(200,200).view(-1, 1,200,200)\n",
    "        self._to_linear = None\n",
    "        self.conv(self.x)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self._to_linear, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "        \n",
    "    def conv(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=(2, 2))\n",
    "#         print()\n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size =(2, 2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, kernel_size =(2, 2))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0] * x[0].shape[1] * x[0].shape[2]\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "#         print(self._to_linear)\n",
    "#         type(x)\n",
    "        x = x.view(-1, self._to_linear) ##\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.softmax(self.fc2(x), dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-synthesis",
   "metadata": {},
   "source": [
    "> **What is going on here?**\n",
    "\n",
    "* first we created a dummy torch tensor `x` with a shape of `1x1x200x200`\n",
    "* we created a `_to_linear` local variable that will helps us to keep tracking our shape.\n",
    "    * The idea here is to say, when we get the shape we want to `multiply` all dimensions and asign the value to `_to_linear`\n",
    "* We created our `conv` function that will help us to update the value of the `_to_linear` when it is called.\n",
    "* First we applied a `relu` activation function to our first `conv1` layer\n",
    "* We then apply `max_pool2d` with a kernel_size of `2x2`\n",
    "* We do this for all `layers`\n",
    "* Since we have assigned `_to_linear` to **None** we want to check if it is still none. If that's the case we will multiply all shapes of the element `x`.\n",
    "* We will create our forward function as usual and imidiately call conv function and get the shape. We will reshape `x` to the new `_to_linear` value, that is flattening it\n",
    "* Apply a `relu` activation function\n",
    "* return the output with softmax activation function applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intended-parade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=67712, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brutal-tennis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67712"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*23*23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-jewelry",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sonic-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-compiler",
   "metadata": {},
   "source": [
    "> We are going to use the `Adam` optimizer\n",
    "* Since we have `one_hot` vectors, we're going to use `MSELoss` metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coral-salmon",
   "metadata": {},
   "source": [
    "### Data\n",
    "> We are now going to load our data and split it into `train` and `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "oriented-helicopter",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cats_v_dogs.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0959e0476d91>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cats_v_dogs.npy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cats_v_dogs.npy'"
     ]
    }
   ],
   "source": [
    "data = np.load('cats_v_dogs.npy', allow_pickle=True)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-outside",
   "metadata": {},
   "source": [
    "> We want to convert this data to `toch.Tensor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([(i[0]) for i in data]).view(-1, 200, 200)\n",
    "y = torch.Tensor([i[1] for i in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.view((-1, 200, 200)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-google",
   "metadata": {},
   "source": [
    "> Split the data into `train` and `test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:150]\n",
    "y_train = y[:150]\n",
    "\n",
    "X_test = X[-150:]\n",
    "y_test = y[-150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-jewelry",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epochs: {epoch+1}/{EPOCHS}')\n",
    "    for i in range(0, len(y_train), BATCH_SIZE):\n",
    "        X_batch = X_train[i: i+BATCH_SIZE].view(-1, 1, 200, 200)\n",
    "        y_batch = y_train[i: i+BATCH_SIZE]\n",
    "        \n",
    "        net.zero_grad() ## or you can say optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net(X_batch)\n",
    "        loss = loss_function(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-perry",
   "metadata": {},
   "outputs": [],
   "source": [
    "total, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        correct_label = torch.argmax(y_test[i])\n",
    "        prediction = torch.argmax(net(X_test[i].view(-1, 1, 200, 200))[0])\n",
    "    \n",
    "        if prediction == correct_label:\n",
    "            correct+=1\n",
    "        total +=1\n",
    "        \n",
    "    print(f\"Accuracy: {correct/total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-attribute",
   "metadata": {},
   "source": [
    "#### Making predictions\n",
    "> We are going to predict one of the image that is in our `test` and visualise it. Remember `cat=0` and `dog=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-culture",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"cat\", \"dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images, labels, cmap=\"gray\"):\n",
    "    plt.figure()\n",
    "    for i in range(len(labels)):\n",
    "        plt.subplot(221+i)\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.imshow(images[i], cmap=cmap)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-knowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = X_test[4:6]\n",
    "\n",
    "predictions = []\n",
    "for image in images:\n",
    "    prediction_index = torch.argmax(net(image.view(-1,1, 200, 200))[0])\n",
    "    predictions.append(prediction_index)\n",
    "plotImages(images, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "miniature-freeze",
   "metadata": {},
   "source": [
    "> Read More **[Docs](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
