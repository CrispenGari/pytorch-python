{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_RNN_LSTM_GRU_BidirectinalRNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYawhjSJwL6p"
      },
      "source": [
        "### RNN - `Recurent Neural Networks`.\n",
        "\n",
        "```python\n",
        "torch.nn.RNN(*args, **kwargs)\n",
        "```\n",
        "\n",
        "Parameters: \n",
        "\n",
        "* ``input_size`` – The number of expected features in the input x\n",
        "\n",
        "* ``hidden_size`` – The number of features in the hidden state h\n",
        "\n",
        "* ``num_layers`` – Number of recurrent layers. E.g., setting ``num_layers=2`` would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: `1``\n",
        "\n",
        "* `nonlinearity` – The non-linearity to use. Can be either `'tanh'` or `'relu'`. Default: `'tanh'`\n",
        "\n",
        "* `bias` – If False, then the layer does not use bias weights `b_ih` and `b_hh`. Default: `True`\n",
        "\n",
        "* `batch_first` – If True, then the input and output tensors are provided as (batch, seq, feature). Default: `False`\n",
        "\n",
        "* `dropout` – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. `Default: 0`\n",
        "\n",
        "* `bidirectional` – If True, becomes a bidirectional RNN. Default: `False`\n",
        "\n",
        "* [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html)\n",
        "\n",
        "The `MNIST` dataset and `RNN`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2fcBBHivt4i"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CamvMi1pyY-2"
      },
      "source": [
        "train = datasets.MNIST('content/drive/', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test = datasets.MNIST('content/drive/', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chMK6Fg3zm-J"
      },
      "source": [
        "train_set = DataLoader(train, batch_size=32, shuffle=True)\n",
        "test_set = DataLoader(test, batch_size=32, shuffle=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jvVVrBs3eWE"
      },
      "source": [
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_zy8GGL3i_O",
        "outputId": "cb67dcc1-72df-45fb-be44-c371f2a6f9ca"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlOMpXDI0Bym"
      },
      "source": [
        "### Simple `RNN`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-CX8UVPzpsq",
        "outputId": "073dd5b7-166b-455c-ae86-30f3c77c2a70"
      },
      "source": [
        "## Hyper Parameters\n",
        "input_size = 28 # (20 features, the number of elements in each row)\n",
        "sequence_length = 28 # (28, the number of rows we have)\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "\n",
        "class SimpleRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(SimpleRNN, self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # initial hidden_state \n",
        "    h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) #(2, 28, 128)\n",
        "    output, h_n = self.rnn(x, h0) # output: tensor of shape (batch_size, seq_length, hidden_size) (32, 28, 128)\n",
        "    output = output[:, -1, :] # (n_batches, num_classes), (32, 10)\n",
        "    return self.fc(output)\n",
        "\n",
        "net = SimpleRNN(input_size, hidden_size, num_layers).to(device)\n",
        "net"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleRNN(\n",
              "  (rnn): RNN(28, 128, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTGnA0wH7aLR"
      },
      "source": [
        "> Trainning the `NN`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_9k0n6v8C5V"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjN8pKRY99OS"
      },
      "source": [
        "### Custom `accuracy` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66OXCoA69Jrz"
      },
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = list(y_true==y_pred).count(True)\n",
        "    total = len(y_true)\n",
        "  net.train()\n",
        "  return correct/total"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZSafa-68C_O"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  for X, y in tqdm(train_set):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    # forward pass\n",
        "    output = net(X.reshape(-1,sequence_length, input_size)).to(device)\n",
        "    y_pred = torch.argmax(output, dim=1)\n",
        "    # loss\n",
        "    loss = criterion(output, y)\n",
        "    # backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # update the weights\n",
        "    optimizer.step()\n",
        "  acc = accuracy(y, y_pred)\n",
        "  print(f\"\\nEpochs: {epoch+1}/{EPOCHS} Loss: {loss.item():.3f}, Accuracy: {acc:.3f}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqe8p6u5Egwq"
      },
      "source": [
        "### Model Evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htBcIv5H8DIL",
        "outputId": "49a9b7fb-d887-47c7-c5f2-9a8252ab8d76"
      },
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device).squeeze(1)\n",
        "            y = y.to(device=device)\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "    return num_correct / num_samples\n",
        "check_accuracy(train_set, net)\n",
        "check_accuracy(test_set, net)"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9280, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C75txHBA8DLT"
      },
      "source": [
        "### Gated Recurrent Unit `(GRU)` Net.\n",
        "\n",
        "Parameters: \n",
        "\n",
        "* ``input_size`` – The number of expected features in the input x\n",
        "\n",
        "* ``hidden_size`` – The number of features in the hidden state h\n",
        "\n",
        "* ``num_layers`` – Number of recurrent layers. E.g., setting ``num_layers=2`` would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: `1``\n",
        "\n",
        "* `nonlinearity` – The non-linearity to use. Can be either `'tanh'` or `'relu'`. Default: `'tanh'`\n",
        "\n",
        "* `bias` – If False, then the layer does not use bias weights `b_ih` and `b_hh`. Default: `True`\n",
        "\n",
        "* `batch_first` – If True, then the input and output tensors are provided as (batch, seq, feature). Default: `False`\n",
        "\n",
        "* `dropout` – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. `Default: 0`\n",
        "\n",
        "* `bidirectional` – If True, becomes a bidirectional RNN. Default: `False`\n",
        "\n",
        "* [Docs](https://pytorch.org/docs/stable/generated/torch.nn.GRU.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4KvXdbdJNQk",
        "outputId": "ab76dcb9-4110-4552-fe39-344afa04fded"
      },
      "source": [
        "\n",
        "# Hyper parameters\n",
        "input_size = 28 \n",
        "sequence_length = 28 \n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layer = num_layers\n",
        "    self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h0 = torch.zeros(self.num_layer, x.size(0), self.hidden_size).to(device)\n",
        "    output, _ = self.gru(x, h0)\n",
        "    output = output[:, -1, :]\n",
        "    return self.fc(output)\n",
        "\n",
        "net = GRU(input_size, hidden_size, num_layers).to(device)\n",
        "net"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRU(\n",
              "  (gru): GRU(28, 128, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ot2Y94s8JNbJ"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7lN4vGRLCCY"
      },
      "source": [
        "### Trainning  the GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIiC72i5JNe0",
        "outputId": "925f14d3-a23e-47da-db2e-65ad63dc9083"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  for X, y in tqdm(train_set):\n",
        "    X = X.to(device).reshape(-1, sequence_length, input_size)\n",
        "    y = y.to(device)\n",
        "    # forward pass\n",
        "    output = net(X).to(device)\n",
        "    y_pred = torch.argmax(output, dim=1)\n",
        "    # loss\n",
        "    loss = criterion(output, y)\n",
        "    #backward pass\n",
        "    loss.backward()\n",
        "    # update the weights\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  acc = accuracy(y, y_pred)\n",
        "  print(f\"\\nEpochs: {epoch+1}/{EPOCHS} Loss: {loss.item():.3f}, Accuracy: {acc:.3f}\\n\")"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 172.68it/s]\n",
            "  1%|          | 17/1875 [00:00<00:10, 169.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 1/10 Loss: 0.060, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 173.75it/s]\n",
            "  1%|          | 18/1875 [00:00<00:10, 175.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 2/10 Loss: 0.141, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 176.08it/s]\n",
            "  1%|          | 18/1875 [00:00<00:10, 177.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 3/10 Loss: 0.040, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 177.38it/s]\n",
            "  1%|          | 18/1875 [00:00<00:10, 172.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 4/10 Loss: 0.007, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 175.70it/s]\n",
            "  1%|          | 18/1875 [00:00<00:10, 173.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 5/10 Loss: 0.013, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 179.80it/s]\n",
            "  1%|          | 18/1875 [00:00<00:10, 176.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 6/10 Loss: 0.020, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 178.49it/s]\n",
            "  1%|          | 18/1875 [00:00<00:10, 179.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 7/10 Loss: 0.014, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 177.39it/s]\n",
            "  1%|          | 15/1875 [00:00<00:12, 148.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 8/10 Loss: 0.207, Accuracy: 0.938\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 174.92it/s]\n",
            "  1%|          | 18/1875 [00:00<00:10, 177.64it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 9/10 Loss: 0.000, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:10<00:00, 174.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 10/10 Loss: 0.030, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx_wSCDbN_Ds"
      },
      "source": [
        "### Evaluating the `GRU`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK9tQry7JNhy",
        "outputId": "a959a611-9fba-418d-b455-457859b3fe74"
      },
      "source": [
        "print(\"Train acc: \", check_accuracy(train_set, net).item())\n",
        "print(\"Test acc: \", check_accuracy(test_set, net).item())"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc:  0.9958833456039429\n",
            "Test acc:  0.9902999997138977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWjOZorwOxFv"
      },
      "source": [
        "### Long Short Term Memory `LSTM` RNN\n",
        "\n",
        "Parameters: \n",
        "\n",
        "* ``input_size`` – The number of expected features in the input x\n",
        "\n",
        "* ``hidden_size`` – The number of features in the hidden state h\n",
        "\n",
        "* ``num_layers`` – Number of recurrent layers. E.g., setting ``num_layers=2`` would mean stacking two RNNs together to form a stacked RNN, with the second RNN taking in outputs of the first RNN and computing the final results. Default: `1``\n",
        "\n",
        "* `nonlinearity` – The non-linearity to use. Can be either `'tanh'` or `'relu'`. Default: `'tanh'`\n",
        "\n",
        "* `bias` – If False, then the layer does not use bias weights `b_ih` and `b_hh`. Default: `True`\n",
        "\n",
        "* `batch_first` – If True, then the input and output tensors are provided as (batch, seq, feature). Default: `False`\n",
        "\n",
        "* `dropout` – If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. `Default: 0`\n",
        "\n",
        "* `bidirectional` – If True, becomes a bidirectional RNN. Default: `False`\n",
        "\n",
        "* ``proj_size`` – If > 0, will use LSTM with projections of corresponding size. Default: `0`\n",
        "\n",
        "The differents between ``LSTM`` and other `RNN's` is that `LSTM` accept a hidden (h0) state and a cell (c0) state:\n",
        "\n",
        "\n",
        "* `h_0` of shape ``(num_layers * num_directions, batch, hidden_size)``: tensor containing the initial hidden state for each element in the batch. If the LSTM is bidirectional, num_directions should be 2, else it should be 1. If `proj_size > `0 was specified, the shape has to be `(num_layers * num_directions, batch, proj_size)`.\n",
        "\n",
        "* `c_0` of shape `(num_layers * num_directions, batch, hidden_size)`: tensor containing the initial cell state for each element in the batch.\n",
        "\n",
        "> If `(h_0, c_0)` is not provided, both `h_0` and `c_0` default to zero.\n",
        "\n",
        "[Docs](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh3XLYBuJNn3",
        "outputId": "fa593dc9-a252-4957-ff0a-54f329394d06"
      },
      "source": [
        "\n",
        "# Hyper parameters\n",
        "input_size = 28 \n",
        "sequence_length = 28 \n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(LSTM, self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "                    #(    number_of_layers, batch_size, hiden_size)\n",
        "    c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "    output, _ = self.lstm(x, (h_0, c_0))\n",
        "    output = output[:, -1, :]\n",
        "\n",
        "    return self.fc(output)\n",
        "\n",
        "net = LSTM(input_size, hidden_size, num_layers).to(device)\n",
        "net"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieHVAOMB8DPB"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BXigg0iR4o5"
      },
      "source": [
        "### Training a `LSTM`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJgFacJu8DRx",
        "outputId": "a88e1919-56f7-45a5-d6e2-ecee8e876382"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  for X, y in tqdm(train_set):\n",
        "    X = X.to(device).reshape(-1, sequence_length, input_size)\n",
        "    y = y.to(device)\n",
        "    # forward pass\n",
        "    output = net(X).to(device)\n",
        "    y_pred = torch.argmax(output, dim=1)\n",
        "    # loss\n",
        "    loss = criterion(output, y)\n",
        "    #backward pass\n",
        "    loss.backward()\n",
        "    # update the weights\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  acc = accuracy(y, y_pred)\n",
        "  print(f\"\\nEpochs: {epoch+1}/{EPOCHS} Loss: {loss.item():.3f}, Accuracy: {acc:.3f}\\n\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 160.97it/s]\n",
            "  1%|          | 17/1875 [00:00<00:11, 167.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 1/10 Loss: 0.113, Accuracy: 0.938\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 163.87it/s]\n",
            "  1%|          | 17/1875 [00:00<00:11, 166.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 2/10 Loss: 0.020, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 162.44it/s]\n",
            "  1%|          | 16/1875 [00:00<00:11, 156.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 3/10 Loss: 0.110, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 163.70it/s]\n",
            "  1%|          | 17/1875 [00:00<00:11, 162.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 4/10 Loss: 0.227, Accuracy: 0.938\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 162.86it/s]\n",
            "  1%|          | 17/1875 [00:00<00:11, 162.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 5/10 Loss: 0.004, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 162.04it/s]\n",
            "  1%|          | 17/1875 [00:00<00:11, 162.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 6/10 Loss: 0.002, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 163.54it/s]\n",
            "  1%|          | 17/1875 [00:00<00:11, 164.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 7/10 Loss: 0.102, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 163.36it/s]\n",
            "  1%|          | 17/1875 [00:00<00:11, 164.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 8/10 Loss: 0.032, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 162.06it/s]\n",
            "  1%|          | 17/1875 [00:00<00:11, 167.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 9/10 Loss: 0.003, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:11<00:00, 164.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 10/10 Loss: 0.001, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scLspZATSRhX"
      },
      "source": [
        "### Evaluating the `LSTM` model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6aUHkyXSDis",
        "outputId": "8bb3975a-9af8-470c-c418-319f0a6908d2"
      },
      "source": [
        "print(\"Train acc: \", check_accuracy(train_set, net).item())\n",
        "print(\"Test acc: \", check_accuracy(test_set, net).item())"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc:  0.9919833540916443\n",
            "Test acc:  0.9869999885559082\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngy1fW87Se1O"
      },
      "source": [
        "### Bidirectional `RNN`\n",
        "To make a recurrent `NN` bidirectional we only need to pass the keyword argument `bidirectional=True` and tweek a litle bit in our `forward` method the `h_0` and `c_0` if it is a `LSTM` RNN otherwise we only change `h_0` for other RNN and then finnaly change the output layer `in_featurers` to be `2 * hidden_size`.\n",
        "\n",
        "```python\n",
        "...\n",
        "\n",
        "nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "self.fc = nn.Linear(hidden_size * 2, 10)\n",
        "....\n",
        "def forward(self, x):\n",
        "  h_0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
        "                    #(    number_of_layers, batch_size, hiden_size)\n",
        "    c_0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
        "```\n",
        "> Where `2` are `num_directions` number of directions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLSfnQhDSeZW",
        "outputId": "c8868433-f646-4f28-c5d1-45dc35ec2b23"
      },
      "source": [
        "# Hyper parameters\n",
        "input_size = 28 \n",
        "sequence_length = 28 \n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_directions = 2\n",
        "\n",
        "class Bidirectional_LSTM(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers, num_directions):\n",
        "    super(Bidirectional_LSTM, self).__init__()\n",
        "    self.num_layers = num_layers\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_directions = num_directions\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                        num_layers=num_layers, batch_first=True, bidirectional=True)\n",
        "    self.fc = nn.Linear(hidden_size * num_directions, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    h_0 = torch.zeros(self.num_layers * num_directions, x.size(0), self.hidden_size).to(device)\n",
        "                    #(    number_of_layers * num_directions, batch_size, hiden_size)\n",
        "    c_0 = torch.zeros(self.num_layers * num_directions, x.size(0), self.hidden_size).to(device)\n",
        "\n",
        "    output, _ = self.lstm(x, (h_0, c_0))\n",
        "    output = output[:, -1, :]\n",
        "\n",
        "    return self.fc(output)\n",
        "\n",
        "net = Bidirectional_LSTM(input_size, hidden_size, num_layers, num_directions).to(device)\n",
        "net"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bidirectional_LSTM(\n",
              "  (lstm): LSTM(28, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEfXk_74VCry"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMJGPhOUnvu"
      },
      "source": [
        "### Trainning the `Bidirectional LSTM`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P16ePb0ScKS",
        "outputId": "28016484-baef-4d05-c2fe-8a0137674a36"
      },
      "source": [
        "EPOCHS = 10\n",
        "for epoch in range(EPOCHS):\n",
        "  for X, y in tqdm(train_set):\n",
        "    X = X.to(device).reshape(-1, sequence_length, input_size)\n",
        "    y = y.to(device)\n",
        "    # forward pass\n",
        "    output = net(X).to(device)\n",
        "    y_pred = torch.argmax(output, dim=1)\n",
        "    # loss\n",
        "    loss = criterion(output, y)\n",
        "    #backward pass\n",
        "    loss.backward()\n",
        "    # update the weights\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  acc = accuracy(y, y_pred)\n",
        "  print(f\"\\nEpochs: {epoch+1}/{EPOCHS} Loss: {loss.item():.3f}, Accuracy: {acc:.3f}\\n\")"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 112.07it/s]\n",
            "  1%|          | 12/1875 [00:00<00:16, 112.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 1/10 Loss: 0.342, Accuracy: 0.906\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 113.31it/s]\n",
            "  1%|          | 12/1875 [00:00<00:16, 110.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 2/10 Loss: 0.039, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 114.28it/s]\n",
            "  1%|          | 11/1875 [00:00<00:17, 108.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 3/10 Loss: 0.009, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 114.01it/s]\n",
            "  1%|          | 11/1875 [00:00<00:17, 107.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 4/10 Loss: 0.003, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 113.13it/s]\n",
            "  1%|          | 11/1875 [00:00<00:17, 107.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 5/10 Loss: 0.039, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 113.18it/s]\n",
            "  1%|          | 12/1875 [00:00<00:16, 114.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 6/10 Loss: 0.005, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 111.65it/s]\n",
            "  1%|          | 12/1875 [00:00<00:16, 115.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 7/10 Loss: 0.038, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 114.25it/s]\n",
            "  1%|          | 12/1875 [00:00<00:16, 115.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 8/10 Loss: 0.003, Accuracy: 1.000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 112.32it/s]\n",
            "  1%|          | 11/1875 [00:00<00:18, 102.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 9/10 Loss: 0.039, Accuracy: 0.969\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 112.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epochs: 10/10 Loss: 0.064, Accuracy: 0.938\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmvW3LFWUw4R"
      },
      "source": [
        "### Evaluating the `Bidirectional` NN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IGmgiqSUuPb",
        "outputId": "94345ec8-bd04-4cc3-cc87-7e1a83fc8a76"
      },
      "source": [
        "print(\"Train acc: \", check_accuracy(train_set, net).item())\n",
        "print(\"Test acc: \", check_accuracy(test_set, net).item())"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc:  0.9943833351135254\n",
            "Test acc:  0.9868999719619751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soEzOQBtXMTm"
      },
      "source": [
        "### Implementing achitecture in `pytorch`.\n",
        "\n",
        "`RNN`\n",
        "\n",
        "```python\n",
        "                                   \n",
        "        [ input ]               [ hidden ] <-------|\n",
        "            |                        |             |\n",
        "            |______           _______|             |         \n",
        "                   [ combined]                     |\n",
        "            __________|    |__________             |\n",
        "            |                         |            |\n",
        "            |                         |            |\n",
        "         [ i2o ]                    [ i2h ]        |\n",
        "            |                          |           |\n",
        "            |                          |----->-----|\n",
        "        [ softmax ]\n",
        "            |\n",
        "            |\n",
        "        [ output ]\n",
        "\n",
        "key:\n",
        "i2o = input to output\n",
        "i2h = input to hidden\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sg-DPmZPWLHM",
        "outputId": "de130856-d691-44e7-f7be-8c5c226c5e66"
      },
      "source": [
        "# Hyper parameters\n",
        "input_size = 28 \n",
        "sequence_length = 28 \n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_directions = 2\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
        "    self.i2o = nn.Linear(input_size + hidden_size, 10)\n",
        "    self.softmax = nn.LogSoftmax(dim=1)\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "  def forward(self, input_tensor):\n",
        "    combined = torch.cat((input_tensor, torch.zeros_like(input_tensor)), 1)\n",
        "\n",
        "    hidden = self.i2h(combined)\n",
        "    output = self.i2o(combined)\n",
        "    output = self.softmax(output)\n",
        "    return output, hidden\n",
        "net = RNN(input_size, hidden_size)\n",
        "net"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (i2h): Linear(in_features=156, out_features=128, bias=True)\n",
              "  (i2o): Linear(in_features=156, out_features=10, bias=True)\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    }
  ]
}