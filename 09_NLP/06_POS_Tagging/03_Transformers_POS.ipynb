{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_Transformers_POS.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn60Q4u8A_lw"
      },
      "source": [
        "---\n",
        "Author: **`Crispen Gari`**\n",
        "\n",
        "Date: **`2021-09-09`**\n",
        "\n",
        "Topic: **`Part of Speech Tagging (PoS) with transformers.`**\n",
        "\n",
        "Language: **`Python`**\n",
        "\n",
        "Library: **`Pytorch`**\n",
        "\n",
        "Main: **`Natural Language Processing (NLP)`**\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6f9EMS4BzFw"
      },
      "source": [
        "### Transformers in PoS Tagging (Fine Tunning)\n",
        "\n",
        "In the previous notebook we leant how to use BiLSTM to perform a Part of Speech Tagging. Today we are going to make use of pretrained [TRansformers](https://arxiv.org/abs/1706.03762) specfically the [BERT](https://arxiv.org/abs/1810.04805) model to perform the same task.\n",
        "\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SocXmxyLA24j",
        "outputId": "3cabdcd7-972b-4ae2-a5fd-b43ea54d5fd9"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 29.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wY9zXyvJA_Jo",
        "outputId": "d60b0a7a-0e8f-4a7c-aa3a-6ac981d86821"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "from torchtext.legacy import data, datasets\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import os, time, random, functools\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.9.0+cu102'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQyU0Iw3DBSp"
      },
      "source": [
        "### Seeds and Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT0aCNCXA_Gx",
        "outputId": "435629a8-52b1-4910-d75b-70e2a1a05f3c"
      },
      "source": [
        "\n",
        "SEED = 42\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjNQiLdmDQj5"
      },
      "source": [
        "### BERT Tokenizer\n",
        "This tokenizer defines how the text processed for the model, but most importantly it contains the vocabulary that the BERT model was trained with. We will be using the `bert-base-uncased` tokenizer model, which was trained with lower cased text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWBewWgoA_Eh"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNBoiD5VD9o3"
      },
      "source": [
        "In order to use pretrained models for NLP the vocabulary used needs to exactly match that of the pretrained model.\n",
        "\n",
        "Another thing that we need to do is make sure the input sequence is formatted in the same way in which the BERT model was trained.\n",
        "\n",
        "BERT was trained on sequences that begin with a ``[CLS]`` token. Example:\n",
        "\n",
        "```py\n",
        "text = [\"i\", \"love\", \"python\", \"ai\"]\n",
        "\n",
        "# will be\n",
        "text = [\"[CLS]\", \"i\", \"love\", \"python\", \"ai\"]\n",
        "```\n",
        "\n",
        "Along with making our vocabularies match we also need to make sure our padding and unk tokens match those used in the pretrained model. By default `TorchText` uses `<pad>` and `<unk>`, but the BERT model uses `[PAD]` and `[UNK]`.\n",
        "\n",
        "Let's have a look at bert special tokens\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nVY022IA_BY",
        "outputId": "1688f42f-d968-4213-948c-1ebcaccea8b1"
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, pad_token, unk_token)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] [PAD] [UNK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-D4vRc5AE-mU"
      },
      "source": [
        "We are mainly interested in the actual integer representations of the special tokens. This is because we aren't using TorchText's vocabulary module, but using the one provided by the pretrained model.\n",
        "\n",
        "We can find those by executing the following cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFkwcFYdA--n",
        "outputId": "470a4f59-6293-498a-ac8e-1d952f8a0ca1"
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "# OR\n",
        "\"\"\"\n",
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
        "\"\"\"\n",
        "print(init_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 0 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH5qBDjVFhGG"
      },
      "source": [
        "Another this is that our pretrained model was trained with a sequence of maximum length which is `512`. We need to make sure that our sequences also matches this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZEyOjpoA-7Y",
        "outputId": "dcc846d1-0cc6-4c19-e4f3-2ec7831f8efc"
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes[\"bert-base-uncased\"]\n",
        "max_input_length"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYga0cabGGIj"
      },
      "source": [
        "Next we need to create some helper functions.\n",
        "\n",
        "The first helper function will cut sequences of tokens to desired maximum length specified by our pretrained model and then converts the tokens into indexes by passing them throught the vocabulary. This is what we will be using on our input sequnences we want to tag.\n",
        "\n",
        "Note that we acually cut tokens to `max_input_length-1`. This is because we want to add the `[CLS]` token at the begining of the sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajz_mcxfA-5R"
      },
      "source": [
        "def cut_and_convert_to_ids(tokens, tokenizer, max_input_length=512):\n",
        "  tokens = tokens[:max_input_length - 1]\n",
        "  return tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04wKEqXjHF7A"
      },
      "source": [
        "The second helper function simply cuts the sequence to the maximum length. This is used for our tags. We do not pass the tags through pretrained model's vocabulary as the vocab was only built for English sentences, and not for part-of-speech tags. We will be building the tag vocabulary ourselves."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmjWTGzAA-2E"
      },
      "source": [
        "def cut_to_max_length(tokens, max_input_length):\n",
        "  return tokens[:max_input_length - 1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmj1yV1jHzSg"
      },
      "source": [
        "\n",
        "We need to pass the above two functions to the Field, the TorchText abstraction that handles a lot of the data processing for us. We make use of Python's functools that allow us to pass functions which already have some of their arguments supplied."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PULg80zA-zL"
      },
      "source": [
        "text_preprocessor = functools.partial(\n",
        "    cut_and_convert_to_ids,\n",
        "    tokenizer=tokenizer,\n",
        "    max_input_length =max_input_length\n",
        ")\n",
        "tag_preprocessor = functools.partial(\n",
        "    cut_to_max_length,\n",
        "    max_input_length =max_input_length\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcXq-W7UIP8g"
      },
      "source": [
        "### Fields\n",
        "\n",
        "For the `TEXT` field, which will be processing the sequences we want to tag, we first tell TorchText that we do not want to use a vocabulary with `use_vocab = False`. As our model is uncased, we also want to ensure all text is lowercased with `lower=True`. The preprocessing argument is a function applied to sequences after they have been tokenized, but before they are numericalized. As we have set `use_vocab` to false, they will never actually be numericalized, and as we are using TorchText's POS datasets they have also already been tokenized - so the argument to this will just be applied to the sequence of tokens. This is where our help functions from above come in handy and `text_preprocessor` will both numericalize our data using the pretrained model's vocabulary, as well as cutting it to the maximum length. The remaining four arguments define the special tokens required by the pretrained model.\n",
        "\n",
        "For the ``UD_TAGS`` field, we need to ensure the length of our tags matches the length of our text sequence. As we have added a ``[CLS]`` token to the beginning of the text sequence, we need to do the same with the sequence of tags. We do this by adding a ``<pad>`` token to the beginning which we will later tell our model to not use when calculating losses or accuracy. We won't have unknown tags in our sequence of tags, so we set the ``unk_token`` to None. Finally, we pass our ``tag_preprocessor`` defined above, which simply cuts the tags to the maximum length our pretrained model can handle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25spZrqsA-wJ"
      },
      "source": [
        "TEXT = data.Field(\n",
        "    use_vocab=False,\n",
        "    preprocessing = text_preprocessor,\n",
        "    init_token = init_token_idx,\n",
        "    pad_token = pad_token_idx,\n",
        "    unk_token= unk_token_idx\n",
        ")\n",
        "\n",
        "UD_TAGS = data.Field(unk_token=None,\n",
        "                     init_token=\"<pad>\",\n",
        "                     preprocessing=tag_preprocessor\n",
        "                    )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNRV4hWoJmXB"
      },
      "source": [
        "Then we will define which fields defined above correspond to which fields in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8z29DKeEA-tK"
      },
      "source": [
        "fields = ((\"text\", TEXT), (\"tags\", UD_TAGS))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClZDVqX2J5P9"
      },
      "source": [
        "We will then loads the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz9UOOsKA-qH"
      },
      "source": [
        "train_data, valid_data, test_data = datasets.UDPOS.splits(\n",
        "    fields\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QtrYRBTKHMu"
      },
      "source": [
        "Now we can check our examples and see that they are already numericalised."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5XApIXwA-nU",
        "outputId": "e4900415-cce7-4a06-d877-6e05a54be049"
      },
      "source": [
        "print(vars(train_data.examples[0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': [100, 1011, 100, 1024, 100, 2749, 2730, 100, 100, 2632, 1011, 100, 1010, 1996, 14512, 2012, 1996, 8806, 1999, 1996, 2237, 1997, 100, 1010, 2379, 1996, 100, 3675, 1012], 'tags': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAuqu4GWKby0"
      },
      "source": [
        "Next we are going to build the vocabulary of the tags."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzT5aECtA-kf"
      },
      "source": [
        "UD_TAGS.build_vocab(train_data)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm-XlVdiA-hg",
        "outputId": "20150757-b65f-458a-8cdf-26322a844581"
      },
      "source": [
        "print(UD_TAGS.vocab.stoi)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(None, {'<pad>': 0, 'NOUN': 1, 'PUNCT': 2, 'VERB': 3, 'PRON': 4, 'ADP': 5, 'DET': 6, 'PROPN': 7, 'ADJ': 8, 'AUX': 9, 'ADV': 10, 'CCONJ': 11, 'PART': 12, 'NUM': 13, 'SCONJ': 14, 'X': 15, 'INTJ': 16, 'SYM': 17})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNUfpTyBKpus"
      },
      "source": [
        "### Iterators\n",
        "\n",
        "Again as from the previous notebook we are going to define our iterators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvyuP-9oA-eq"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    device= device,\n",
        "    batch_size= BATCH_SIZE\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wo76_ydLMnx"
      },
      "source": [
        "### Model\n",
        "Next up is defining our model. The model is relatively simple, with all of the complicated parts contained inside the BERT module which we do not have to worry about. We can think of the BERT as an embedding layer and all we do is add a linear layer on top of these embeddings to predict the tag for each token in the input sequence.\n",
        "\n",
        "![img](https://camo.githubusercontent.com/4b9ff887ad76b826189f0721505dc1cc248492a8/68747470733a2f2f6769746875622e636f6d2f62656e747265766574742f7079746f7263682d706f732d74616767696e672f626c6f622f6d61737465722f6173736574732f706f732d626572742e706e673f7261773d31)\n",
        "\n",
        "One thing to note is that we do not define an embedding_dim for our model, it is the size of the output of the pretrained BERT model and we cannot change it. Thus, we simply get the embedding_dim from the model's hidden_size attribute.\n",
        "\n",
        "BERT also wants sequences with the batch element first, hence we permute our input sequence before passing it to BERT."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eujak4JTA-bn"
      },
      "source": [
        "class BERTPoSTagger(nn.Module):\n",
        "  def __init__(self, bert, output_dim, dropout=.5):\n",
        "    super(BERTPoSTagger, self).__init__()\n",
        "\n",
        "    self.bert = bert\n",
        "    embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "\n",
        "    self.fc = nn.Linear(embedding_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text):\n",
        "    # text = [sent len, batch size]\n",
        "    text = text.permute(1, 0)\n",
        "    # text = [batch size, sent len]\n",
        "    embedded = self.dropout(self.bert(text)[0])\n",
        "    # embedded = [batch size, seq len, emb dim]\n",
        "    embedded = embedded.permute(1, 0, 2)\n",
        "    # embedded = [sent len, batch size, emb dim]\n",
        "    out = self.fc(self.dropout(embedded))\n",
        "    # out = [sent len, batch size, output_dim]\n",
        "    return out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEcOuLxAMzvi"
      },
      "source": [
        "Next, we load the actual pretrained BERT uncased model - before we only loaded the tokenizer associated with the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5c306VSA-Yv",
        "outputId": "48601d20-1efb-4e0e-bfe5-070f67b252d8"
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyEbrCIPM5Sp"
      },
      "source": [
        "### Model Instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCU7xDvSA-V3",
        "outputId": "bcde4f5d-1e4b-45ad-cb1c-e93a26923642"
      },
      "source": [
        "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
        "DROPOUT = 0.25\n",
        "\n",
        "model = BERTPoSTagger(bert,\n",
        "                      OUTPUT_DIM, \n",
        "                      DROPOUT)\n",
        "model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTPoSTagger(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=18, bias=True)\n",
              "  (dropout): Dropout(p=0.25, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAr9ett8NEQZ"
      },
      "source": [
        "### Counting model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBP7rtr7A-QZ",
        "outputId": "36b27fbb-c1bc-4c4d-dfc2-e8e7b47b13fb"
      },
      "source": [
        "\n",
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of paramaters: 109,496,082\n",
            "Total tainable parameters: 109,496,082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IjLBjxXNR01"
      },
      "source": [
        "Next, we define our optimizer. Usually when fine-tuning you want to use a lower learning rate than normal, this is because we don't want to drastically change the parameters as it may cause our model to forget what it has learned. This phenomenon is called catastrophic forgetting.\n",
        "\n",
        "We pick ``5e-5 (0.00005)`` as it is one of the three values recommended in the BERT paper. Again, there may be better values for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1_oW_UjNDTa"
      },
      "source": [
        "\n",
        "LEARNING_RATE = 5e-5\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URZcfHRQNoRR"
      },
      "source": [
        "### Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYDD7b7TNDQz"
      },
      "source": [
        "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00yee8tmNxOA"
      },
      "source": [
        "Model and criterion to device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqkLoU41NDPF"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lskp50Q1N0Gt"
      },
      "source": [
        "Categorical accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPEzaQfxNDLL"
      },
      "source": [
        "def categorical_accuracy(preds, y, tag_pad_idx):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
        "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
        "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).to(device)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7Iwsi13N6Ex"
      },
      "source": [
        "Train and evaluate functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmMPE8Q4NDH8"
      },
      "source": [
        "def train(model, iterator,  optimizer, criterion, tag_pad_idx):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    text = batch.text # text = [sent len, batch size]\n",
        "    tags = batch.tags # tags = [sent len, batch size]\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = model(text)\n",
        "    # predictions = [sent len, batch size, output dim]\n",
        "    predictions = predictions.view(-1, predictions.shape[-1])\n",
        "    # predictions = [sent len * batch size, output dim]\n",
        "    tags = tags.view(-1) # tags = [sent len * batch size]\n",
        "    loss = criterion(predictions, tags)\n",
        "    acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      text = batch.text # text = [sent len, batch size]\n",
        "      tags = batch.tags # tags = [sent len, batch size]\n",
        "      predictions = model(text)\n",
        "      # predictions = [sent len, batch size, output dim]\n",
        "      predictions = predictions.view(-1, predictions.shape[-1])\n",
        "      # predictions = [sent len * batch size, output dim]\n",
        "      tags = tags.view(-1) # tags = [sent len * batch size]\n",
        "      loss = criterion(predictions, tags)\n",
        "      acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
        "      \n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4LJ_sh-ORcx"
      },
      "source": [
        "### Next we will run the train loop.\n",
        "\n",
        "We are going to have helper functions that will helps us to visualizing our trainig epoch\n",
        "\n",
        "1. Time to string function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCp0Jd7wA-NQ"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "  h = int(sec_elapsed / (60 * 60))\n",
        "  m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "  s = sec_elapsed % 60\n",
        "  return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81rkJLpQOciJ"
      },
      "source": [
        "2. Visualize training epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRGLCkPdOcZQ"
      },
      "source": [
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLGKXkIBOcWm",
        "outputId": "cf3afcdb-6b53-4659-be56-4b0a61427a94"
      },
      "source": [
        "N_EPOCHS = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer,\n",
        "                                criterion, TAG_PAD_IDX)\n",
        "  valid_loss, valid_acc = evaluate(model,\n",
        "                                   valid_iterator,\n",
        "                                   criterion, TAG_PAD_IDX)\n",
        "  \n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(model.state_dict(), 'best-model.pt')\n",
        "  end = time.time()\n",
        "  visualize_training(start, end, train_loss, train_acc,\n",
        "                     valid_loss, valid_acc, title)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/01 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.147 |    0.955 | 0:04:06.03 |\n",
            "| Validation | 0.535 |    0.821 |            |\n",
            "+------------+-------+----------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCOTakaBOlgC"
      },
      "source": [
        "### Evaluating the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocnRPie-OcPt",
        "outputId": "46b105cf-a254-4cf4-e836-c430a18ae024"
      },
      "source": [
        "def visualize_test(start, end, test_loss,\n",
        "                       test_accuracy, title):\n",
        "  data = [\n",
        "       [\"test\", f'{test_loss:.3f}', f'{test_accuracy:.3f}', f\"{hms_string(end - start)}\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "  \n",
        "\n",
        "model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "start = time.time()\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, tag_pad_idx=TAG_PAD_IDX)\n",
        "end = time.time()\n",
        "\n",
        "visualize_test(start, end, test_loss, test_acc, \"MODEL EVALUATION SUMMARY\")\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------------------+\n",
            "|         MODEL EVALUATION SUMMARY         |\n",
            "+----------+-------+----------+------------+\n",
            "| CATEGORY |  LOSS | ACCURACY |        ETA |\n",
            "+----------+-------+----------+------------+\n",
            "| test     | 0.587 |    0.799 | 0:00:04.37 |\n",
            "+----------+-------+----------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tqNVc55OrIh"
      },
      "source": [
        "### Model Inference\n",
        "\n",
        "We'll now see how to use our model to tag actual sentences. This is similar to the inference function from the previous notebook with the tokenization changed to match the format of our pretrained model.\n",
        "\n",
        "If we pass in a string, this means we need to split it into individual tokens which we do by using the tokenize function of the tokenizer. Afterwards, numericalize our tokens the same way we did before, using convert_tokens_to_ids. Then, we add the [CLS] token index to the beginning of the sequence.\n",
        "\n",
        "**Note:** if we forget to add the [CLS] token our results will not be good!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf6wNUryOq_F"
      },
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "def tag_sentence(model, device, sentence, tokenizer, text_field,\n",
        "                 tag_field):\n",
        "  model.eval()\n",
        "\n",
        "  if isinstance(sentence, str):\n",
        "    tokens = tokenizer.tokenize(sentence)\n",
        "  else:\n",
        "    tokens = sentence\n",
        "\n",
        "  if text_field.lower:\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "\n",
        "  numericalized_tokens = tokenizer.convert_tokens_to_ids(tokens)\n",
        "  numericalized_tokens = [text_field.init_token] + numericalized_tokens\n",
        "\n",
        "  unk_idx = text_field.unk_token\n",
        "  unks = [t for t, n in zip(tokens, numericalized_tokens) if n == unk_idx]\n",
        "  token_tensor = torch.LongTensor(numericalized_tokens)\n",
        "  token_tensor = token_tensor.unsqueeze(-1).to(device)\n",
        "  predictions = model(token_tensor)\n",
        "  top_predictions = predictions.argmax(-1)\n",
        "  predicted_tags = [tag_field.vocab.itos[t.item()] for t in top_predictions]\n",
        "  predicted_tags = predicted_tags[1:]\n",
        "  return tokens, predicted_tags, unks\n"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZZbHAWVP7AS"
      },
      "source": [
        "Taking a single example from the train set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN8h01JCOq1h",
        "outputId": "f1d00d31-9cdb-4204-d68f-a852793943f2"
      },
      "source": [
        "example_index = 1\n",
        "\n",
        "sentence = vars(train_data.examples[example_index])['text']\n",
        "actual_tags = vars(train_data.examples[example_index])['tags']\n",
        "print(sentence)\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1031, 100, 4288, 1997, 1037, 9768, 29307, 2097, 2022, 4786, 2149, 4390, 2005, 2086, 2000, 2272, 1012, 1033]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANU2ahl8Obr9",
        "outputId": "6007b579-1821-4fde-9961-00a625fd2e4e"
      },
      "source": [
        "tokens, pred_tags, unks = tag_sentence(model, \n",
        "                                       device, \n",
        "                                       sentence,\n",
        "                                       tokenizer, \n",
        "                                       TEXT, \n",
        "                                       UD_TAGS)\n",
        "\n",
        "print(unks) "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100, 4288, 1997, 1037, 9768, 29307, 2097, 2022, 4786, 2149, 4390, 2005, 2086, 2000, 2272, 1012, 1033]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrJqwkw5QnhU",
        "outputId": "8090e411-0f4c-4726-d251-699e1e192df9"
      },
      "source": [
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "\n",
        "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "PRON\t\tPUNCT\t\t✘\t\t1031\n",
            "VERB\t\tDET\t\t✘\t\t100\n",
            "NOUN\t\tNOUN\t\t✔\t\t4288\n",
            "NOUN\t\tADP\t\t✘\t\t1997\n",
            "NOUN\t\tDET\t\t✘\t\t1037\n",
            "NOUN\t\tADJ\t\t✘\t\t9768\n",
            "NOUN\t\tNOUN\t\t✔\t\t29307\n",
            "NOUN\t\tAUX\t\t✘\t\t2097\n",
            "NOUN\t\tAUX\t\t✘\t\t2022\n",
            "NOUN\t\tVERB\t\t✘\t\t4786\n",
            "NOUN\t\tPRON\t\t✘\t\t2149\n",
            "NOUN\t\tNOUN\t\t✔\t\t4390\n",
            "NOUN\t\tADP\t\t✘\t\t2005\n",
            "NOUN\t\tNOUN\t\t✔\t\t2086\n",
            "VERB\t\tPART\t\t✘\t\t2000\n",
            "VERB\t\tVERB\t\t✔\t\t2272\n",
            "VERB\t\tPUNCT\t\t✘\t\t1012\n",
            "NOUN\t\tPUNCT\t\t✘\t\t1033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6x-RaqEQH8K"
      },
      "source": [
        "Taking as single example from the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kk3oazjA-KY",
        "outputId": "98e32aab-353e-4f4f-82b2-5ae90371ce7b"
      },
      "source": [
        "example_index = 1\n",
        "\n",
        "sentence = vars(valid_data.examples[example_index])['text']\n",
        "actual_tags = vars(valid_data.examples[example_index])['tags']\n",
        "print(sentence)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100, 100, 2006, 100, 4222, 2048, 3633, 2000, 5672, 9150, 100, 2006, 2976, 5434, 1999, 1996, 100, 2181, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lv3pXJ7Qig_"
      },
      "source": [
        "tokens, pred_tags, unks = tag_sentence(model, \n",
        "                                       device, \n",
        "                                       sentence,\n",
        "                                       tokenizer, \n",
        "                                       TEXT, \n",
        "                                       UD_TAGS)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99BBNeu-QidV",
        "outputId": "caa9864f-41a7-4044-8fd1-dde7fb464ec4"
      },
      "source": [
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "\n",
        "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
            "\n",
            "PRON\t\tPUNCT\t\t✘\t\t1031\n",
            "VERB\t\tDET\t\t✘\t\t100\n",
            "NOUN\t\tNOUN\t\t✔\t\t4288\n",
            "NOUN\t\tADP\t\t✘\t\t1997\n",
            "NOUN\t\tDET\t\t✘\t\t1037\n",
            "NOUN\t\tADJ\t\t✘\t\t9768\n",
            "NOUN\t\tNOUN\t\t✔\t\t29307\n",
            "NOUN\t\tAUX\t\t✘\t\t2097\n",
            "NOUN\t\tAUX\t\t✘\t\t2022\n",
            "NOUN\t\tVERB\t\t✘\t\t4786\n",
            "NOUN\t\tPRON\t\t✘\t\t2149\n",
            "NOUN\t\tNOUN\t\t✔\t\t4390\n",
            "NOUN\t\tADP\t\t✘\t\t2005\n",
            "NOUN\t\tNOUN\t\t✔\t\t2086\n",
            "VERB\t\tPART\t\t✘\t\t2000\n",
            "VERB\t\tVERB\t\t✔\t\t2272\n",
            "VERB\t\tPUNCT\t\t✘\t\t1012\n",
            "NOUN\t\tPUNCT\t\t✘\t\t1033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GhyJi8nQOA6"
      },
      "source": [
        "Taking a single example from the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_MY3DAvQReF",
        "outputId": "8e990fb6-cd5f-4043-8011-be674985639a"
      },
      "source": [
        "example_index = 1\n",
        "\n",
        "sentence = vars(test_data.examples[example_index])['text']\n",
        "actual_tags = vars(test_data.examples[example_index])['tags']\n",
        "print(sentence)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100, 2065, 100, 4423, 2006, 2049, 3945, 1011, 3194, 1006, 1998, 2085, 100, 1007, 100, 2046, 1037, 2440, 1011, 26712, 4082, 2291, 1029]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yqpr4DwEQjgG"
      },
      "source": [
        "tokens, pred_tags, unks = tag_sentence(model, \n",
        "                                       device, \n",
        "                                       sentence,\n",
        "                                       tokenizer, \n",
        "                                       TEXT, \n",
        "                                       UD_TAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dcw0MfpQjcp"
      },
      "source": [
        "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
        "\n",
        "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
        "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
        "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql5XRJNKQbgJ"
      },
      "source": [
        "Using our own sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNaUB1fnQbQK"
      },
      "source": [
        "sentence = 'The Queen will deliver a speech about the conflict in North Korea at 1pm tomorrow.'\n",
        "\n",
        "tokens, tags, unks = tag_sentence(model, \n",
        "                                  device, \n",
        "                                  sentence,\n",
        "                                  tokenizer,\n",
        "                                  TEXT, \n",
        "                                  UD_TAGS)\n",
        "\n",
        "print(unks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjT6OAgWQwD4"
      },
      "source": [
        "print(\"Pred. Tag\\tToken\\n\")\n",
        "for token, tag in zip(tokens, tags):\n",
        "    print(f\"{tag}\\t\\t{token}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYVdoCeMQ2Rf"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "We have implemented out POS tagging in pytorch using UD Tags and Transformers. In the following notebook we want to change to make use of the PTB. Basically in the following notebook we are justgoing to use this notebook as our base, and change just a few things.\n",
        "### Credits\n",
        "\n",
        "* [bentrevett](https://github.com/bentrevett/pytorch-pos-tagging/blob/master/1_bilstm.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXCEkZWjRHI-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}