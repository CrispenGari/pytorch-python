{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_Transformers_For_Sentiment_Analy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e0c8f2647de04f63a225cf270fd4e5f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ed91cb08b2e34ed4a4d15e5b9c854109",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_06cb8d4504154d1cb3b081863990a41f",
              "IPY_MODEL_4915816ec90e45f695b04aec64682bfc"
            ]
          }
        },
        "ed91cb08b2e34ed4a4d15e5b9c854109": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06cb8d4504154d1cb3b081863990a41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f417233db9204f22a5d77bbf25f3ac79",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5bf2681e6c674fe1901979eca8823683"
          }
        },
        "4915816ec90e45f695b04aec64682bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_86d405321d3b479fb5689c4dae3cba49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 223kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddc6505b12df41e186f5677c8b38dd29"
          }
        },
        "f417233db9204f22a5d77bbf25f3ac79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5bf2681e6c674fe1901979eca8823683": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86d405321d3b479fb5689c4dae3cba49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddc6505b12df41e186f5677c8b38dd29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48891266e71c40c0a55666b6ae4c2666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3614ac32bd243a9aacb148822fc5a51",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20f385a5dbd44da69b62b4ac14cfc0ee",
              "IPY_MODEL_40ab69c0fc8a47a68c00c41b9207a136"
            ]
          }
        },
        "f3614ac32bd243a9aacb148822fc5a51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20f385a5dbd44da69b62b4ac14cfc0ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0fabc9c212754288a5fc2eb455d444fe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_09e9f466970646909eabb5ac2804de4e"
          }
        },
        "40ab69c0fc8a47a68c00c41b9207a136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_52eb99d064bf46ab8e4113e7c495ea0b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 65.0B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f684bd470a03417e8b3ac87d60199be3"
          }
        },
        "0fabc9c212754288a5fc2eb455d444fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "09e9f466970646909eabb5ac2804de4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52eb99d064bf46ab8e4113e7c495ea0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f684bd470a03417e8b3ac87d60199be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4f9e849249b46c8834eb5c0ead3da66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6a3ab0f24807401f91540981e46ada8b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7e8441312b8b4f799e16cecfa33cb115",
              "IPY_MODEL_eb4a245bbac845e695f73979731ff435"
            ]
          }
        },
        "6a3ab0f24807401f91540981e46ada8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e8441312b8b4f799e16cecfa33cb115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2db4eed92d494dfd8ac14e66c67f5198",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_070d5630ef7a4c3e8cefc2cea08539b1"
          }
        },
        "eb4a245bbac845e695f73979731ff435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_31482a8b0e074ad284fdfaee68cf19f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 4.64MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e3f483189969496886a0d98f2b22e29d"
          }
        },
        "2db4eed92d494dfd8ac14e66c67f5198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "070d5630ef7a4c3e8cefc2cea08539b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31482a8b0e074ad284fdfaee68cf19f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e3f483189969496886a0d98f2b22e29d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1IyNPD3VvmB"
      },
      "source": [
        "### Transformers for seintiment analyisis.\n",
        "\n",
        "In this notebook we are going to use the Transformer model **(BERT)**  which was first introduced in this [paper](https://arxiv.org/abs/1706.03762) and it is from this [paper](https://arxiv.org/abs/1810.04805).\n",
        "\n",
        "\n",
        "**BERT** -> **B**idirectional **E**ncoder **R**epresentations from **T**ransformers.\n",
        "\n",
        "\n",
        "Transformer models are considerably larger than anything else covered from the previous notebooks. As such we are going to use the [trasformers library](https://github.com/huggingface/transformers) to get pre-trained transformers and use them as our embedding layers. We will freeze (not train) the transformer and only train the remainder of the model which learns from the representations produced by the transformer. In this case we will be using a multi-layer bi-directional GRU, however any model can learn from these representations.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zO-Gv7AYDWm"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xaiRcwcT5_-"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKMajBR_XwdW"
      },
      "source": [
        "\n",
        "The transformer has already been trained with a specific vocabulary, which means we need to train with the exact same vocabulary and also tokenize our data in the same way that the transformer did when it was initially trained.\n",
        "\n",
        "Luckily, the transformers library has tokenizers for each of the transformer models provided. In this case we are using the ``BERT`` model which ignores casing . We get this by loading the pre-trained ``bert-base-uncased`` tokenizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2pvDtdoZHwS"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SswnvnojY6KG",
        "outputId": "a185fd19-6ed2-4093-db70-92f2e691abeb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 27.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "e0c8f2647de04f63a225cf270fd4e5f9",
            "ed91cb08b2e34ed4a4d15e5b9c854109",
            "06cb8d4504154d1cb3b081863990a41f",
            "4915816ec90e45f695b04aec64682bfc",
            "f417233db9204f22a5d77bbf25f3ac79",
            "5bf2681e6c674fe1901979eca8823683",
            "86d405321d3b479fb5689c4dae3cba49",
            "ddc6505b12df41e186f5677c8b38dd29",
            "48891266e71c40c0a55666b6ae4c2666",
            "f3614ac32bd243a9aacb148822fc5a51",
            "20f385a5dbd44da69b62b4ac14cfc0ee",
            "40ab69c0fc8a47a68c00c41b9207a136",
            "0fabc9c212754288a5fc2eb455d444fe",
            "09e9f466970646909eabb5ac2804de4e",
            "52eb99d064bf46ab8e4113e7c495ea0b",
            "f684bd470a03417e8b3ac87d60199be3",
            "d4f9e849249b46c8834eb5c0ead3da66",
            "6a3ab0f24807401f91540981e46ada8b",
            "7e8441312b8b4f799e16cecfa33cb115",
            "eb4a245bbac845e695f73979731ff435",
            "2db4eed92d494dfd8ac14e66c67f5198",
            "070d5630ef7a4c3e8cefc2cea08539b1",
            "31482a8b0e074ad284fdfaee68cf19f6",
            "e3f483189969496886a0d98f2b22e29d"
          ]
        },
        "id": "s7zyc8bKXwaX",
        "outputId": "9b5ede8b-2a9b-47a8-85d3-b75faf986eaf"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0c8f2647de04f63a225cf270fd4e5f9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48891266e71c40c0a55666b6ae4c2666",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4f9e849249b46c8834eb5c0ead3da66",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu6aXDTQZgx_"
      },
      "source": [
        "### Checking the Vocabulary size in the `tokenizer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qVOM8jhXwXx",
        "outputId": "2297e78d-edbb-4d9d-bfdc-6705ff19042b"
      },
      "source": [
        "tokenizer.vocab_size, len(tokenizer.vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30522, 30522)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOZsk5oEZwXs"
      },
      "source": [
        "### Using a tokenizer to tokenize a string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdoIu6tCXwUe",
        "outputId": "5063748d-afa7-4b4e-a7af-d5f683c1a5e8"
      },
      "source": [
        "tokens = tokenizer.tokenize(\"This is what we call AI\")\n",
        "tokens"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'what', 'we', 'call', 'ai']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-FvZ7QhaHfO"
      },
      "source": [
        "## Numericalize Tokens\n",
        "We can numericalize tokens using our vocabulary using ``tokenizer.convert_tokens_to_ids``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfDaFbiQXwR5",
        "outputId": "57bf5691-4cf2-4c5e-ec85-7b2d4b1e7625"
      },
      "source": [
        "tokens_to_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "tokens_to_ids"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2023, 2003, 2054, 2057, 2655, 9932]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suZTZV9ualqI"
      },
      "source": [
        "> Converting back to string representation we call the `tokenizer.convert_ids_to_tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fawP30nPXwO2",
        "outputId": "5e5d6177-be07-4301-bef8-89b5e470c224"
      },
      "source": [
        "tokenizer.convert_ids_to_tokens(tokens_to_ids)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this', 'is', 'what', 'we', 'call', 'ai']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwaDcfrya8E1"
      },
      "source": [
        "The transformer was also trained with special tokens to mark the beginning and end of the sentence [more deteil](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel). As well as a standard padding and unknown token. We can also get these from the tokenizer.\n",
        "\n",
        "**Note:** the tokenizer does have a beginning of sequence and end of sequence attributes (``bos_token`` and ``eos_token``) but these are not set and should not be used for this transformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEGhz1oMXwLu",
        "outputId": "cc628c6f-2d95-4003-919a-792a104812fb"
      },
      "source": [
        "init_token = (tokenizer.cls_token, tokenizer.cls_token_id)\n",
        "sep_token = (tokenizer.sep_token, tokenizer.sep_token_id)\n",
        "pad_token = (tokenizer.pad_token, tokenizer.pad_token_id)\n",
        "unk_token = (tokenizer.unk_token, tokenizer.unk_token_id)\n",
        "bos_token = (tokenizer.bos_token, tokenizer.bos_token_id)\n",
        "eos_token = (tokenizer.eos_token, tokenizer.eos_token_id)\n",
        "\n",
        "init_token, sep_token, pad_token, unk_token, bos_token, eos_token"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using bos_token, but it is not set yet.\n",
            "Using eos_token, but it is not set yet.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('[CLS]', 101),\n",
              " ('[SEP]', 102),\n",
              " ('[PAD]', 0),\n",
              " ('[UNK]', 100),\n",
              " (None, None),\n",
              " (None, None))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz0cDY4-cTJt"
      },
      "source": [
        "Another thing we need to handle is that the model was trained on sequences with a defined maximum length - it does not know how to handle sequences longer than it has been trained on. We can get the maximum length of these input sizes by checking the ``max_model_input_sizes`` for the version of the transformer we want to use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VieEuggMcSv2",
        "outputId": "140223d1-d8bc-428d-b3cb-835e986feb27"
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "max_input_length"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmOOtNW8cpns"
      },
      "source": [
        "Previously we have used the ``spaCy`` tokenizer to tokenize our examples. However we now need to define a function that we will pass to our ``TEXT`` field that will handle all the tokenization for us. It will also cut down the number of tokens to a maximum length. \n",
        "\n",
        "**Note:** that our maximum length is **2** less than the actual maximum length. This is because we need to append two tokens to each sequence, one to the **start** and one to the **end**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjXC2WryXwJA"
      },
      "source": [
        "def tokenize_and_cut(sent):\n",
        "  return tokenizer.tokenize(sent)[:max_input_length-2]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPDifAj9em9E"
      },
      "source": [
        "### Special tokens indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p22JRviledFs",
        "outputId": "687e3712-51f8-4c10-f2da-e4ac66dd31e9"
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101, 102, 0, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tipKbn7Pd-Qo"
      },
      "source": [
        "\n",
        "Now we define our **fields**. The transformer expects the batch dimension to be first, so we set ``batch_first = True``. \n",
        "\n",
        "As we already have the vocabulary for our text, provided by the transformer we set ``use_vocab = False`` to tell torchtext that we'll be handling the vocabulary side of things. \n",
        "\n",
        "We pass our ``tokenize_and_cut`` function as the tokenizer. The preprocessing argument is a function that takes in the example after it has been tokenized, this is where we will convert the tokens to their indexes. \n",
        "\n",
        "Finally, we define the special tokens - making note that we are defining them to be their index value and not their string value, i.e. 100 instead of ``[UNK]`` This is because the sequences will already be converted into indexes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs5pv0m3XwGO"
      },
      "source": [
        "from torchtext.legacy import data, datasets"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqp9qTj8XwDl"
      },
      "source": [
        "TEXT = data.Field(\n",
        "    use_vocab=False,\n",
        "    batch_first = True,\n",
        "    tokenize = tokenize_and_cut,\n",
        "    preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "    init_token = init_token_idx,\n",
        "    eos_token = eos_token_idx,\n",
        "    pad_token = pad_token_idx,\n",
        "    unk_token = unk_token_idx\n",
        ")\n",
        "\n",
        "LABEL = data.LabelField(dtype = torch.float)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csNA5GMMfquW"
      },
      "source": [
        "### Loading the data.\n",
        "We are going to use the `IMDB` dataset for movies reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4-6VP9mXwBA",
        "outputId": "6ba5d374-d1a3-47d5-8d71-76c01aabddd5"
      },
      "source": [
        "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
        "valid_data, test_data = test_data.split(random_state = random.seed(SEED))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\raclImdb_v1.tar.gz:   0%|          | 0.00/84.1M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:02<00:00, 37.3MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DROAPNHVXv-f",
        "outputId": "a3e0348a-43dc-4a90-fd0d-d5369ce53541"
      },
      "source": [
        "print(f\"TRAINING EXAMPLES: {len(train_data)}\")\n",
        "print(f\"VALIDATION EXAMPLES: {len(valid_data)}\")\n",
        "print(f\"TESTING EXAMPLES: {len(test_data)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING EXAMPLES: 25000\n",
            "VALIDATION EXAMPLES: 17500\n",
            "TESTING EXAMPLES: 7500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFwqRRIcgkyo"
      },
      "source": [
        "### Checking a single example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzdVd-hXXv7O",
        "outputId": "898c851a-4a9c-41e9-eb85-d3e075b3b0e2"
      },
      "source": [
        "print(vars(train_data.examples[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': [2004, 2467, 1010, 6801, 5691, 2066, 2023, 2031, 3816, 4391, 1012, 2017, 2593, 2293, 2009, 2030, 2017, 5223, 2009, 1010, 1998, 2025, 3071, 2097, 2066, 2023, 3185, 1012, 2023, 3065, 1996, 7339, 1997, 1996, 15978, 1010, 2029, 2003, 2242, 1045, 7714, 2514, 2003, 2242, 2590, 2000, 5136, 1012, 2017, 2089, 5223, 2068, 1010, 2017, 2089, 4366, 2000, 3305, 2068, 1998, 2514, 2004, 2295, 2017, 2064, 14396, 1010, 2021, 7539, 2023, 3185, 2097, 2191, 2017, 2228, 2055, 2082, 5008, 2015, 2013, 1037, 2367, 7339, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 3185, 2003, 2915, 4498, 2478, 1037, 2192, 1011, 2218, 4950, 1010, 2242, 2008, 1045, 2228, 2573, 3243, 2092, 2004, 2009, 3084, 2009, 2062, 12689, 1012, 2009, 2003, 2409, 3294, 2013, 1996, 15978, 2391, 1997, 3193, 1010, 2013, 2037, 1000, 6416, 1000, 2000, 2155, 26256, 2015, 1010, 2035, 2877, 2039, 1996, 2502, 2154, 1000, 5717, 2154, 1000, 1999, 2029, 2027, 2024, 4041, 2006, 1037, 9288, 2012, 2037, 2082, 1012, 5717, 2154, 2515, 2025, 3749, 6998, 1010, 2021, 6414, 7534, 1037, 12185, 2012, 1996, 3268, 1997, 2048, 11587, 2402, 3337, 1998, 11082, 1996, 4378, 5630, 2005, 3209, 1012, 2256, 5346, 2875, 1996, 3337, 2024, 2242, 3816, 2090, 11883, 1998, 11150, 1010, 2021, 2664, 2057, 2024, 2187, 5457, 2004, 2000, 2339, 2048, 6623, 2402, 3337, 2052, 2079, 2107, 1037, 2518, 1012, 2027, 2024, 3491, 2000, 2022, 10889, 3671, 1010, 5171, 9454, 3337, 2877, 6623, 3268, 1010, 1998, 2065, 2057, 2134, 1005, 1056, 2113, 2054, 2027, 2020, 4041, 2057, 2876, 1005, 1056, 5987, 1037, 2518, 1006, 2027, 2191, 2009, 3154, 2802, 1996, 2878, 3185, 2008, 2053, 1011, 2028, 2842, 4282, 2055, 2037, 2933, 1007, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 3772, 2003, 5186, 2204, 6195, 1996, 2048, 5889, 2024, 3143, 4242, 2015, 1012, 2057, 2064, 2069, 3246, 2000, 2156, 2062, 2147, 2013, 1996, 2119, 1997, 2068, 1999, 1996, 2925, 1012, 2750, 2129, 2023, 2003, 1037, 7214, 3550, 3185, 1010, 2028, 3685, 2393, 2021, 5060, 1996, 5793, 12319, 2000, 8902, 25438, 3170, 1012, 11130, 1998, 7213, 2024, 11228, 6588, 2714, 2000, 4388, 5671, 1998, 7758, 1047, 2571, 27495, 1010, 1006, 2025, 2061, 2172, 1999, 3504, 1010, 2021, 1999, 5450, 1007, 2004, 2619, 2040, 2038, 18800, 8902, 25438, 3170, 2200, 8077, 1010, 1045, 2071, 2156, 1996, 12319, 1998, 2009, 2003, 2471, 5121, 2241, 2006, 2009, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 1996, 5025, 9288, 2003, 3491, 2083, 9867, 8629, 2012, 1996, 2082, 1998, 2003, 2028, 1997, 1996, 2087, 27017, 2477, 1045, 2031, 2412, 2464, 1012, 1045, 2001, 3294, 1999, 5213, 2044, 3773, 2009, 1010, 1998, 2049, 1037, 3110, 2008, 12237, 2105, 2005, 1037, 2096, 1012, 2009, 2003, 2200, 12689, 1998, 2092, 1011, 2589, 1010, 1998, 2009, 2003, 2200, 3697, 2000, 3422, 1012, 1026, 7987, 1013, 1028, 1026, 7987, 1013, 1028, 2035, 1999, 2035, 5717, 2154, 2003, 2019, 6581, 3185, 1010, 1998, 1045, 2228, 3071, 2323, 2012, 2560, 4638, 2009, 2041, 1012, 1999, 1996, 2627, 1010, 2057, 2031, 2467, 3432, 11180, 15978, 1000, 18224, 15069, 2015, 1000, 1998, 5071, 2008, 2593, 2027, 2020, 6897, 2135, 17502, 2005, 7071], 'label': 'pos'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGI6EX3Zg6e9"
      },
      "source": [
        "We can use the ``convert_ids_to_tokens`` to transform these indexes back into readable tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93f8Fm3Xv4g",
        "outputId": "68a0604e-91fe-4d67-dd6d-47d3494c101b"
      },
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[1])['text'])\n",
        "print(tokens)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['as', 'always', ',', 'controversial', 'movies', 'like', 'this', 'have', 'mixed', 'reviews', '.', 'you', 'either', 'love', 'it', 'or', 'you', 'hate', 'it', ',', 'and', 'not', 'everyone', 'will', 'like', 'this', 'movie', '.', 'this', 'shows', 'the', 'perspective', 'of', 'the', 'killers', ',', 'which', 'is', 'something', 'i', 'personally', 'feel', 'is', 'something', 'important', 'to', 'consider', '.', 'you', 'may', 'hate', 'them', ',', 'you', 'may', 'claim', 'to', 'understand', 'them', 'and', 'feel', 'as', 'though', 'you', 'can', 'relate', ',', 'but', 'regardless', 'this', 'movie', 'will', 'make', 'you', 'think', 'about', 'school', 'shooting', '##s', 'from', 'a', 'different', 'perspective', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'movie', 'is', 'shot', 'entirely', 'using', 'a', 'hand', '-', 'held', 'camera', ',', 'something', 'that', 'i', 'think', 'works', 'quite', 'well', 'as', 'it', 'makes', 'it', 'more', 'realistic', '.', 'it', 'is', 'told', 'completely', 'from', 'the', 'killers', 'point', 'of', 'view', ',', 'from', 'their', '\"', 'missions', '\"', 'to', 'family', 'outing', '##s', ',', 'all', 'leading', 'up', 'the', 'big', 'day', '\"', 'zero', 'day', '\"', 'in', 'which', 'they', 'are', 'planning', 'on', 'a', 'massacre', 'at', 'their', 'school', '.', 'zero', 'day', 'does', 'not', 'offer', 'answers', ',', 'but', 'merely', 'presents', 'a', 'glimpse', 'at', 'the', 'lives', 'of', 'two', 'troubled', 'young', 'boys', 'and', 'lets', 'the', 'audience', 'decide', 'for', 'themselves', '.', 'our', 'feelings', 'towards', 'the', 'boys', 'are', 'something', 'mixed', 'between', 'sympathy', 'and', 'hatred', ',', 'but', 'yet', 'we', 'are', 'left', 'confused', 'as', 'to', 'why', 'two', 'ordinary', 'young', 'boys', 'would', 'do', 'such', 'a', 'thing', '.', 'they', 'are', 'shown', 'to', 'be', 'surprisingly', 'normal', ',', 'typical', 'teenage', 'boys', 'leading', 'ordinary', 'lives', ',', 'and', 'if', 'we', 'didn', \"'\", 't', 'know', 'what', 'they', 'were', 'planning', 'we', 'wouldn', \"'\", 't', 'expect', 'a', 'thing', '(', 'they', 'make', 'it', 'clear', 'throughout', 'the', 'whole', 'movie', 'that', 'no', '-', 'one', 'else', 'knows', 'about', 'their', 'plan', ')', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'acting', 'is', 'extremely', 'good', 'considering', 'the', 'two', 'actors', 'are', 'complete', 'unknown', '##s', '.', 'we', 'can', 'only', 'hope', 'to', 'see', 'more', 'work', 'from', 'the', 'both', 'of', 'them', 'in', 'the', 'future', '.', 'despite', 'how', 'this', 'is', 'a', 'fictional', '##ized', 'movie', ',', 'one', 'cannot', 'help', 'but', 'notice', 'the', 'obvious', 'similarities', 'to', 'col', '##umb', '##ine', '.', 'calvin', 'and', 'andre', 'are', 'scar', '##ily', 'similar', 'to', 'eric', 'harris', 'and', 'dylan', 'k', '##le', '##bold', ',', '(', 'not', 'so', 'much', 'in', 'looks', ',', 'but', 'in', 'manner', ')', 'as', 'someone', 'who', 'has', 'researched', 'col', '##umb', '##ine', 'very', 'extensively', ',', 'i', 'could', 'see', 'the', 'similarities', 'and', 'it', 'is', 'almost', 'certainly', 'based', 'on', 'it', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'the', 'actual', 'massacre', 'is', 'shown', 'through', 'surveillance', 'cameras', 'at', 'the', 'school', 'and', 'is', 'one', 'of', 'the', 'most', 'chilling', 'things', 'i', 'have', 'ever', 'seen', '.', 'i', 'was', 'completely', 'in', 'shock', 'after', 'seeing', 'it', ',', 'and', 'its', 'a', 'feeling', 'that', 'stays', 'around', 'for', 'a', 'while', '.', 'it', 'is', 'very', 'realistic', 'and', 'well', '-', 'done', ',', 'and', 'it', 'is', 'very', 'difficult', 'to', 'watch', '.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'all', 'in', 'all', 'zero', 'day', 'is', 'an', 'excellent', 'movie', ',', 'and', 'i', 'think', 'everyone', 'should', 'at', 'least', 'check', 'it', 'out', '.', 'in', 'the', 'past', ',', 'we', 'have', 'always', 'simply', 'branded', 'killers', '\"', 'psycho', '##path', '##s', '\"', 'and', 'assumed', 'that', 'either', 'they', 'were', 'biological', '##ly', 'wired', 'for', 'disaster']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4kmJfUhG9U"
      },
      "source": [
        "### Building labels vocabulary\n",
        "Although we've handled the vocabulary for the text, we still need to build the vocabulary for the labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ5wrSotXv1u",
        "outputId": "dde97099-6ed4-4ccd-841e-f861a11173c8"
      },
      "source": [
        "LABEL.build_vocab(train_data)\n",
        "LABEL.vocab.stoi"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(None, {'neg': 0, 'pos': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T40d9QZkhchn"
      },
      "source": [
        "### Creating Iterators\n",
        "As before we are going to use the `BucketIterator`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U5L-0CJXvyg"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, test_iterator, validation_iterator = data.BucketIterator.splits(\n",
        "    (train_data, test_data, valid_data),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device = device\n",
        ")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiwiPXgZiQv2"
      },
      "source": [
        "### Building the Model.\n",
        "\n",
        "1. First we will load the pretrainned model. **making sure to load the same model as we did for the tokenizer.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSiBGMGUiHKp",
        "outputId": "a4462d6f-a490-4918-e769-8043399ef3bd"
      },
      "source": [
        "from transformers import BertModel\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "bert"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKtZgoili7FL"
      },
      "source": [
        "2. Defining our actual model\n",
        "\n",
        "Instead of using an embedding layer to get embeddings for our text, we'll be using the pre-trained transformer model. These embeddings will then be fed into a GRU to produce a prediction for the sentiment of the input sentence. We get the embedding dimension size (called the hidden_size) from the transformer via its config attribute. The rest of the initialization is standard.\n",
        "\n",
        "Within the forward pass, we wrap the transformer in a no_grad to ensure no gradients are calculated over this part of the model. The transformer actually returns the embeddings for the whole sequence as well as a pooled output. The [documentation](https://huggingface.co/transformers/model_doc/bert.html#transformers.BertModel) states that the pooled output is \"usually not a good summary of the semantic content of the input, you’re often better with averaging or pooling the sequence of hidden-states for the whole input sequence\", hence we will not be using it. The rest of the forward pass is the standard implementation of a recurrent model, where we take the hidden state over the final time-step, and pass it through a linear layer to get our predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoAmHU6XkB-M"
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiBiR0Pkir83"
      },
      "source": [
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self, bert, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim,\n",
        "                          num_layers = n_layers, bidirectional = bidirectional,\n",
        "                          batch_first = True, dropout = 0 if n_layers < 2 else dropout\n",
        "                          )\n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        #text = [batch size, sent len]   \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text)[0]\n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        _, hidden = self.rnn(embedded)\n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])     \n",
        "        #hidden = [batch size, hid dim]\n",
        "        output = self.fc(hidden)\n",
        "        #output = [batch size, out dim]\n",
        "        return output"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs9PzoZamjWt"
      },
      "source": [
        "### Model Hyper parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL52sanVi26c"
      },
      "source": [
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "\n",
        "model = BERTGRUSentiment(bert,\n",
        "                         HIDDEN_DIM,\n",
        "                         OUTPUT_DIM,\n",
        "                         N_LAYERS,\n",
        "                         BIDIRECTIONAL,\n",
        "                         DROPOUT)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TvsJlBTnK6V"
      },
      "source": [
        "### Counting trainable parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyWfcUuKi24K",
        "outputId": "b0d6bab5-0a4f-4a6b-bdee-856ee4145534"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
        "\n",
        "print(f'The model has {count_trainable_params(model):,} trainable parameters')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 112,241,409 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOSBaiRLnpFE"
      },
      "source": [
        "### Freezing bert model parameters\n",
        "\n",
        "In order to freeze paramers (not train them) we need to set their ``requires_grad`` attribute to ``False``. To do this, we simply loop through all of the ``named_parameters`` in our model and if they're a part of the bert transformer model, we set ``requires_grad = False``."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pqmVHIJi2zO"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  if name.startswith('bert'):\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0g2DOcJi2xp"
      },
      "source": [
        "We can now see that our model has under 3M trainable parameters, making it almost comparable to the FastText model. However, the text still has to propagate through the transformer which causes training to take considerably longer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsdWEwUxi2tK",
        "outputId": "3f5d1d75-a30a-42db-d33c-21043288929d"
      },
      "source": [
        "print(f'The model has {count_trainable_params(model):,} trainable parameters')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,759,169 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aTmFo2doXFN"
      },
      "source": [
        "We can double check the names of the trainable parameters, ensuring they make sense. As we can see, they are all the parameters of the GRU (rnn) and the linear layer (out)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PHxIEb6i2pu",
        "outputId": "32f684ed-ec34-4532-f349-18a04dd0b1ff"
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1zeMqumofZF"
      },
      "source": [
        "### Trainning the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWrtuJA0i2jx"
      },
      "source": [
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2y5m0Hrolp6"
      },
      "source": [
        "### Pushing the model to the device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kutMJrNIi2h_"
      },
      "source": [
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OnzBxClov0T"
      },
      "source": [
        "### The accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0DoKapUi2eI"
      },
      "source": [
        "def binary_accuracy(y_preds, y_true):\n",
        "  #round predictions to the closest integer\n",
        "  rounded_preds = torch.round(torch.sigmoid(y_preds))\n",
        "  correct = (rounded_preds == y_true).float() #convert into float for division \n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tl1eP46o2DD"
      },
      "source": [
        "### The trainning and evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtQH9ek7i2bQ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        text = batch.text\n",
        "        predictions = model(text).squeeze(1)\n",
        "        loss = criterion(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text = batch.text\n",
        "            predictions = model(text).squeeze(1)\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeyPAoBKpDe-"
      },
      "source": [
        "We'll also create a function to tell us how long an epoch takes to compare training times between models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-gRhYTZpAzZ"
      },
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ2Q2HbCpPMN"
      },
      "source": [
        "### Training and evaluation loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mZ2Vkpv0YC8"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwkhE_5zpGFs",
        "outputId": "750c4624-eaa2-4d8d-b960-8e896b47e771"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, validation_iterator, criterion)\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-model.pt')\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 27m 20s\n",
            "\tTrain Loss: 0.238 | Train Acc: 90.48%\n",
            "\t Val. Loss: 0.193 |  Val. Acc: 92.13%\n",
            "Epoch: 02 | Epoch Time: 27m 25s\n",
            "\tTrain Loss: 0.209 | Train Acc: 91.97%\n",
            "\t Val. Loss: 0.207 |  Val. Acc: 91.50%\n",
            "Epoch: 03 | Epoch Time: 27m 27s\n",
            "\tTrain Loss: 0.178 | Train Acc: 93.02%\n",
            "\t Val. Loss: 0.193 |  Val. Acc: 92.38%\n",
            "Epoch: 04 | Epoch Time: 27m 28s\n",
            "\tTrain Loss: 0.155 | Train Acc: 94.12%\n",
            "\t Val. Loss: 0.203 |  Val. Acc: 92.74%\n",
            "Epoch: 05 | Epoch Time: 27m 28s\n",
            "\tTrain Loss: 0.129 | Train Acc: 95.22%\n",
            "\t Val. Loss: 0.198 |  Val. Acc: 92.40%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA7sClAHq_0d"
      },
      "source": [
        "### Evaluating the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "0lEIhvZDpMtz",
        "outputId": "b5ed12cf-a4a6-4de6-f290-4771aa692ba8"
      },
      "source": [
        "model.load_state_dict(torch.load('best-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-5b2409098519>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best-model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'best-model.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0XeQIoXrQnk"
      },
      "source": [
        "### Inference\n",
        "We'll then use the model to test the sentiment of some sequences. We tokenize the input sequence, trim it down to the maximum length, add the special tokens to either side, convert it to a tensor, add a fake batch dimension and then pass it through our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJZAcXVBrPDQ"
      },
      "source": [
        "def predict_sentiment(model, tokenizer, sentence):\n",
        "    model.eval()\n",
        "    tokens = tokenizer.tokenize(sentence)[:max_input_length-2]\n",
        "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(0)\n",
        "    prediction = torch.sigmoid(model(tensor))\n",
        "    return prediction.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7BqcjotrQa8"
      },
      "source": [
        "while True:\n",
        "  review = input(\"Enter a review\\nexit to quit:\\n\")\n",
        "  if review.lower() == \"quit\":\n",
        "    break\n",
        "  print(predict_sentiment(model, tokenizer, review))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Yms9hAuyUZb"
      },
      "source": [
        "### Credits.\n",
        "\n",
        "[bentrevett](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/6%20-%20Transformers%20for%20Sentiment%20Analysis.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfMuHdb1rQZP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ9dzYNprQT_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFvA7Im2rQPy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}